.nh
.TH "X86-VGATHERPF1DPS-VGATHERPF1QPS-VGATHERPF1DPD-VGATHERPF1QPD" "7" "May 2019" "TTMO" "Intel x86-64 ISA Manual"
.SH NAME
VGATHERPF1DPS-VGATHERPF1QPS-VGATHERPF1DPD-VGATHERPF1QPD - SPARSE PREFETCH PACKED SP-DP DATA VALUES WITH SIGNED DWORD, SIGNED QWORD INDICES USING T1 HINT
.TS
allbox;
l l l l l 
l l l l l .
\fB\fCOpcode/Instruction\fR	\fB\fCOp/En\fR	\fB\fC64/32 bit Mode Support\fR	\fB\fCCPUID Feature Flag\fR	\fB\fCDescription\fR
T{
EVEX.512.66.0F38.W0 C6 /2 /vsib VGATHERPF1DPS vm32z {k1}
T}
	A	V/V	AVX512PF	T{
Using signed dword indices, prefetch sparse byte memory locations containing single\-precision data using opmask k1 and T1 hint.
T}
T{
EVEX.512.66.0F38.W0 C7 /2 /vsib VGATHERPF1QPS vm64z {k1}
T}
	A	V/V	AVX512PF	T{
Using signed qword indices, prefetch sparse byte memory locations containing single\-precision data using opmask k1 and T1 hint.
T}
T{
EVEX.512.66.0F38.W1 C6 /2 /vsib VGATHERPF1DPD vm32y {k1}
T}
	A	V/V	AVX512PF	T{
Using signed dword indices, prefetch sparse byte memory locations containing double\-precision data using opmask k1 and T1 hint.
T}
T{
EVEX.512.66.0F38.W1 C7 /2 /vsib VGATHERPF1QPD vm64z {k1}
T}
	A	V/V	AVX512PF	T{
Using signed qword indices, prefetch sparse byte memory locations containing double\-precision data using opmask k1 and T1 hint.
T}
.TE

.SH INSTRUCTION OPERAND ENCODING
.TS
allbox;
l l l l l l 
l l l l l l .
Op/En	Tuple Type	Operand 1	Operand 2	Operand 3	Operand 4
A	Tuple1 Scalar	T{
BaseReg (R): VSIB:base, VectorReg(R): VSIB:index
T}
	NA	NA	NA
.TE

.SS Description
.PP
The instruction conditionally prefetches up to sixteen 32\-bit or eight
64\-bit integer byte data elements. The elements are specified via the
VSIB (i.e., the index register is an zmm, holding packed indices).
Elements will only be prefetched if their corresponding mask bit is one.

.PP
Lines prefetched are loaded into to a location in the cache hierarchy
specified by a locality hint (T1):

.RS
.IP \(bu 2
T1 (temporal data)—prefetch data into the second level cache.

.RE

.PP
[PS data] For dword indices, the instruction will prefetch sixteen
memory locations. For qword indices, the instruction will prefetch eight
values.

.PP
[PD data] For dword and qword indices, the instruction will prefetch
eight memory locations.

.PP
Note that:

.PP
(1) The prefetches may happen in any order (or not at all). The
instruction is a hint.

.PP
(2) The mask is left unchanged.

.PP
(3) Not valid with 16\-bit effective addresses. Will deliver a #UD
fault.

.PP
(4) No FP nor memory faults may be produced by this instruction.

.PP
(5) Prefetches do not handle cache line splits

.PP
(6) A #UD is signaled if the memory operand is encoded without the
SIB byte.

.SS Operation
.PP
.RS

.nf
BASE\_ADDR stands for the memory operand base address (a GPR); may not exist
VINDEX stands for the memory operand vector of indices (a vector register)
SCALE stands for the memory operand scalar (1, 2, 4 or 8)
DISP is the optional 1, 2 or 4 byte displacement
PREFETCH(mem, Level, State) Prefetches a byte memory location pointed by ‘mem’ into the cache level specified by ‘Level’; a request
for exclusive/ownership is done if ‘State’ is 1. Note that the memory location ignore cache line splits. This operation is considered a
hint for the processor and may be skipped depending on implementation.

.fi
.RE

.SS VGATHERPF1DPS (EVEX encoded version)
.PP
.RS

.nf
(KL, VL) = (16, 512)
FOR j←0 TO KL\-1
    i←j * 32
    IF k1[j]
        Prefetch( [BASE\_ADDR + SignExtend(VINDEX[i+31:i]) * SCALE + DISP], Level=1, RFO = 0)
    FI;
ENDFOR

.fi
.RE

.SS VGATHERPF1DPD (EVEX encoded version)
.PP
.RS

.nf
(KL, VL) = (8, 512)
FOR j←0 TO KL\-1
    i←j * 64
    k←j * 32
    IF k1[j]
        Prefetch( [BASE\_ADDR + SignExtend(VINDEX[k+31:k]) * SCALE + DISP], Level=1, RFO = 0)
    FI;
ENDFOR

.fi
.RE

.SS VGATHERPF1QPS (EVEX encoded version)
.PP
.RS

.nf
(KL, VL) = (8, 256)
FOR j←0 TO KL\-1
    i←j * 64
    IF k1[j]
        Prefetch( [BASE\_ADDR + SignExtend(VINDEX[i+63:i]) * SCALE + DISP], Level=1, RFO = 0)
    FI;
ENDFOR

.fi
.RE

.SS VGATHERPF1QPD (EVEX encoded version)
.PP
.RS

.nf
(KL, VL) = (8, 512)
FOR j←0 TO KL\-1
    i←j * 64
    k←j * 64
    IF k1[j]
        Prefetch( [BASE\_ADDR + SignExtend(VINDEX[k+63:k]) * SCALE + DISP], Level=1, RFO = 0)
    FI;
ENDFOR

.fi
.RE

.SS Intel C/C++ Compiler Intrinsic Equivalent
.PP
.RS

.nf
VGATHERPF1DPD void \_mm512\_mask\_prefetch\_i32gather\_pd(\_\_m256i vdx, \_\_mmask8 m, void * base, int scale, int hint);

VGATHERPF1DPS void \_mm512\_mask\_prefetch\_i32gather\_ps(\_\_m512i vdx, \_\_mmask16 m, void * base, int scale, int hint);

VGATHERPF1QPD void \_mm512\_mask\_prefetch\_i64gather\_pd(\_\_m512i vdx, \_\_mmask8 m, void * base, int scale, int hint);

VGATHERPF1QPS void \_mm512\_mask\_prefetch\_i64gather\_ps(\_\_m512i vdx, \_\_mmask8 m, void * base, int scale, int hint);

.fi
.RE

.SS SIMD Floating\-Point Exceptions
.PP
None

.SS Other Exceptions
.PP
See Exceptions Type E12NP.

.SH SEE ALSO
.PP
x86\-manpages(7) for a list of other x86\-64 man pages.

.SH COLOPHON
.PP
This UNOFFICIAL, mechanically\-separated, non\-verified reference is
provided for convenience, but it may be incomplete or broken in
various obvious or non\-obvious ways. Refer to Intel® 64 and IA\-32
Architectures Software Developer’s Manual for anything serious.

.br
This page is generated by scripts; therefore may contain visual or semantical bugs. Please report them (or better, fix them) on https://github.com/ttmo-O/x86-manpages.

.br
MIT licensed by TTMO 2020 (Turkish Unofficial Chamber of Reverse Engineers - https://ttmo.re).
