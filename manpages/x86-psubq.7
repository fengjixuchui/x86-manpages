.nh
.TH "X86-PSUBQ" "7" "May 2019" "TTMO" "Intel x86-64 ISA Manual"
.SH NAME
PSUBQ - SUBTRACT PACKED QUADWORD INTEGERS
.TS
allbox;
l l l l l 
l l l l l .
\fB\fCOpcode/Instruction\fR	\fB\fCOp/En\fR	\fB\fC64/32 bit Mode Support\fR	\fB\fCCPUID Feature Flag\fR	\fB\fCDescription\fR
NP 0F FB /mm2/m64	A	V/V	SSE2	T{
Subtract quadword integer in mm2 /m64.
T}
66 0F FB /xmm2/m128	A	V/V	SSE2	T{
Subtract packed quadword integers in xmm2 /m128.
T}
T{
VEX.128.66.0F.WIG FB/r VPSUBQ xmm1, xmm2, xmm3/m128
T}
	B	V/V	AVX	T{
Subtract packed quadword integers in xmm2.
T}
T{
VEX.256.66.0F.WIG FB /r VPSUBQ ymm1, ymm2, ymm3/m256
T}
	B	V/V	AVX2	T{
Subtract packed quadword integers in ymm2.
T}
T{
EVEX.128.66.0F.W1 FB /r VPSUBQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
T}
	C	V/V	AVX512VL AVX512F	T{
Subtract packed quadword integers in xmm3/m128/m64bcst from xmm2 and store in xmm1 using writemask k1.
T}
T{
EVEX.256.66.0F.W1 FB /r VPSUBQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
T}
	C	V/V	AVX512VL AVX512F	T{
Subtract packed quadword integers in ymm3/m256/m64bcst from ymm2 and store in ymm1 using writemask k1.
T}
T{
EVEX.512.66.0F.W1 FB/r VPSUBQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
T}
	C	V/V	AVX512F	T{
Subtract packed quadword integers in zmm3/m512/m64bcst from zmm2 and store in zmm1 using writemask k1.
T}
.TE

.PP
.RS

.PP
1\&. See note in Section 2.4, “AVX and SSE Instruction Exception
Specification” in the Intel® 64 and IA\-32 Architectures Software
Developer’s Manual, Volume 3A.

.RE

.SH INSTRUCTION OPERAND ENCODING
.TS
allbox;
l l l l l l 
l l l l l l .
Op/En	Tuple Type	Operand 1	Operand 2	Operand 3	Operand 4
A	NA	ModRM:reg (r, w)	ModRM:r/m (r)	NA	NA
B	NA	ModRM:reg (w)	VEX.vvvv (r)	ModRM:r/m (r)	NA
C	Full	ModRM:reg (w)	EVEX.vvvv (r)	ModRM:r/m (r)	NA
.TE

.SH DESCRIPTION
.PP
Subtracts the second operand (source operand) from the first operand
(destination operand) and stores the result in the destination operand.
When packed quadword operands are used, a SIMD subtract is performed.
When a quadword result is too large to be represented in 64 bits
(overflow), the result is wrapped around and the low 64 bits are written
to the destination element (that is, the carry is ignored).

.PP
Note that the (V)PSUBQ instruction can operate on either unsigned or
signed (two’s complement notation) integers; however, it does not set
bits in the EFLAGS register to indicate overflow and/or a carry. To
prevent undetected overflow conditions, software must control the ranges
of the values upon which it operates.

.PP
In 64\-bit mode and not encoded with VEX/EVEX, using a REX prefix in the
form of REX.R permits this instruction to access additional registers
(XMM8\-XMM15).

.PP
Legacy SSE version 64\-bit operand: The source operand can be a quadword
integer stored in an MMX technology register or a 64\-bit memory
location.

.PP
128\-bit Legacy SSE version: The second source operand is an XMM register
or a 128\-bit memory location. The first source operand and destination
operands are XMM registers. Bits (MAXVL\-1:128) of the corresponding YMM
destination register remain unchanged.

.PP
VEX.128 encoded version: The second source operand is an XMM register or
a 128\-bit memory location. The first source operand and destination
operands are XMM registers. Bits (MAXVL\-1:128) of the destination YMM
register are zeroed.

.PP
VEX.256 encoded versions: The second source operand is an YMM register
or an 256\-bit memory location. The first source operand and destination
operands are YMM registers. Bits (MAXVL\-1:256) of the corresponding ZMM
register are zeroed.

.PP
EVEX encoded VPSUBQ: The second source operand is a ZMM/YMM/XMM
register, a 512/256/128\-bit memory location or a 512/256/128\-bit vector
broadcasted from a 32/64\-bit memory location. The first source operand
and destination operands are ZMM/YMM/XMM registers. The destination is
conditionally updated with writemask k1.

.SH OPERATION
.SS PSUBQ (with 64\-Bit operands)
.PP
.RS

.nf
DEST[63:0] ← DEST[63:0] − SRC[63:0];

.fi
.RE

.SS PSUBQ (with 128\-Bit operands)
.PP
.RS

.nf
DEST[63:0] ← DEST[63:0] − SRC[63:0];
DEST[127:64] ← DEST[127:64] − SRC[127:64];

.fi
.RE

.SS VPSUBQ (VEX.128 encoded version)
.PP
.RS

.nf
DEST[63:0] ← SRC1[63:0]\-SRC2[63:0]
DEST[127:64] ← SRC1[127:64]\-SRC2[127:64]
DEST[MAXVL\-1:128] ← 0

.fi
.RE

.SS VPSUBQ (VEX.256 encoded version)
.PP
.RS

.nf
DEST[63:0] ← SRC1[63:0]\-SRC2[63:0]
DEST[127:64] ← SRC1[127:64]\-SRC2[127:64]
DEST[191:128] ← SRC1[191:128]\-SRC2[191:128]
DEST[255:192] ← SRC1[255:192]\-SRC2[255:192]
DEST[MAXVL\-1:256] ← 0

.fi
.RE

.SS VPSUBQ (EVEX encoded versions)
.PP
.RS

.nf
(KL, VL) = (2, 128), (4, 256), (8, 512)
FOR j←0 TO KL\-1
    i←j * 64
    IF k1[j] OR *no writemask* THEN
            IF (EVEX.b = 1) AND (SRC2 *is memory*)
                THEN DEST[i+63:i]←SRC1[i+63:i] \- SRC2[63:0]
                ELSE DEST[i+63:i]←SRC1[i+63:i] \- SRC2[i+63:i]
            FI;
        ELSE
            IF *merging\-masking* ; merging\-masking
                THEN *DEST[i+63:i] remains unchanged*
                ELSE *zeroing\-masking*
                        ; zeroing\-masking
                    DEST[i+63:i] ← 0
            FI
    FI;
ENDFOR;
DEST[MAXVL\-1:VL] ← 0

.fi
.RE

.SH INTEL C/C++ COMPILER INTRINSIC EQUIVALENTS
.PP
.RS

.nf
VPSUBQ \_\_m512i \_mm512\_sub\_epi64(\_\_m512i a, \_\_m512i b);

VPSUBQ \_\_m512i \_mm512\_mask\_sub\_epi64(\_\_m512i s, \_\_mmask8 k, \_\_m512i a, \_\_m512i b);

VPSUBQ \_\_m512i \_mm512\_maskz\_sub\_epi64( \_\_mmask8 k, \_\_m512i a, \_\_m512i b);

VPSUBQ \_\_m256i \_mm256\_mask\_sub\_epi64(\_\_m256i s, \_\_mmask8 k, \_\_m256i a, \_\_m256i b);

VPSUBQ \_\_m256i \_mm256\_maskz\_sub\_epi64( \_\_mmask8 k, \_\_m256i a, \_\_m256i b);

VPSUBQ \_\_m128i \_mm\_mask\_sub\_epi64(\_\_m128i s, \_\_mmask8 k, \_\_m128i a, \_\_m128i b);

VPSUBQ \_\_m128i \_mm\_maskz\_sub\_epi64( \_\_mmask8 k, \_\_m128i a, \_\_m128i b);

PSUBQ:\_\_m64 \_mm\_sub\_si64(\_\_m64 m1, \_\_m64 m2)

(V)PSUBQ:\_\_m128i \_mm\_sub\_epi64(\_\_m128i m1, \_\_m128i m2)

VPSUBQ:\_\_m256i \_mm256\_sub\_epi64(\_\_m256i m1, \_\_m256i m2)

.fi
.RE

.SH FLAGS AFFECTED
.PP
None.

.SH NUMERIC EXCEPTIONS
.PP
None.

.SH OTHER EXCEPTIONS
.PP
Non\-EVEX\-encoded instruction, see Exceptions Type 4.

.PP
EVEX\-encoded VPSUBQ, see Exceptions Type E4.

.SH SEE ALSO
.PP
x86\-manpages(7) for a list of other x86\-64 man pages.

.SH COLOPHON
.PP
This UNOFFICIAL, mechanically\-separated, non\-verified reference is
provided for convenience, but it may be incomplete or broken in
various obvious or non\-obvious ways. Refer to Intel® 64 and IA\-32
Architectures Software Developer’s Manual for anything serious.

.br
This page is generated by scripts; therefore may contain visual or semantical bugs. Please report them (or better, fix them) on https://github.com/ttmo-O/x86-manpages.

.br
MIT licensed by TTMO 2020 (Turkish Unofficial Chamber of Reverse Engineers - https://ttmo.re).
