.nh
.TH "X86-VGATHERDPS-VGATHERQPS" "7" "May 2019" "TTMO" "Intel x86-64 ISA Manual"
.SH NAME
VGATHERDPS-VGATHERQPS - GATHER PACKED SP FP VALUES USING SIGNED DWORD-QWORD INDICES
.TS
allbox;
l l l l l 
l l l l l .
\fB\fCOpcode/Instruction\fR	\fB\fCOp/En\fR	\fB\fC64/32 \-bit Mode\fR	\fB\fCCPUID Feature Flag\fR	\fB\fCDescription\fR
T{
VEX.128.66.0F38.W0 92 /r VGATHERDPS xmm1, vm32x, xmm2
T}
	A	V/V	AVX2	T{
Using dword indices specified in xmm1.
T}
T{
VEX.128.66.0F38.W0 93 /r VGATHERQPS xmm1, vm64x, xmm2
T}
	A	V/V	AVX2	T{
Using qword indices specified in xmm1.
T}
T{
VEX.256.66.0F38.W0 92 /r VGATHERDPS ymm1, vm32y, ymm2
T}
	A	V/V	AVX2	T{
Using dword indices specified in ymm1.
T}
T{
VEX.256.66.0F38.W0 93 /r VGATHERQPS xmm1, vm64y, xmm2
T}
	A	V/V	AVX2	T{
Using qword indices specified in xmm1.
T}
.TE

.SH INSTRUCTION OPERAND ENCODING
.TS
allbox;
l l l l l 
l l l l l .
Op/En	Operand 1	Operand 2	Operand 3	Operand 4
A	ModRM:reg (r,w)	T{
BaseReg (R): VSIB:base, VectorReg(R): VSIB:index
T}
	VEX.vvvv (r, w)	NA
.TE

.SH DESCRIPTION
.PP
The instruction conditionally loads up to 4 or 8 single\-precision
floating\-point values from memory addresses specified by the memory
operand (the second operand) and using dword indices. The memory operand
uses the VSIB form of the SIB byte to specify a general purpose register
operand as the common base, a vector register for an array of indices
relative to the base and a constant scale factor.

.PP
The mask operand (the third operand) specifies the conditional load
operation from each memory address and the corresponding update of each
data element of the destination operand (the first operand).
Conditionality is specified by the most significant bit of each data
element of the mask register. If an element’s mask bit is not set, the
corresponding element of the destination register is left unchanged. The
width of data element in the destination register and mask register are
identical. The entire mask register will be set to zero by this
instruction unless the instruction causes an exception.

.PP
Using qword indices, the instruction conditionally loads up to 2 or 4
single\-precision floating\-point values from the VSIB addressing memory
operand, and updates the lower half of the destination register. The
upper 128 or 256 bits of the destination register are zero’ed with qword
indices.

.PP
This instruction can be suspended by an exception if at least one
element is already gathered (i.e., if the exception is triggered by an
element other than the rightmost one with its mask bit set). When this
happens, the destination register and the mask operand are partially
updated; those elements that have been gathered are placed into the
destination register and have their mask bits set to zero. If any traps
or interrupts are pending from already gathered elements, they will be
delivered in lieu of the exception; in this case, EFLAG.RF is set to one
so an instruction breakpoint is not re\-triggered when the instruction is
continued.

.PP
If the data size and index size are different, part of the destination
register and part of the mask register do not correspond to any elements
being gathered. This instruction sets those parts to zero. It may do
this to one or both of those registers even if the instruction triggers
an exception, and even if the instruction triggers the exception before
gathering any elements.

.PP
VEX.128 version: For dword indices, the instruction will gather four
single\-precision floating\-point values. For qword indices, the
instruction will gather two values and zero the upper 64 bits of the
destination.

.PP
VEX.256 version: For dword indices, the instruction will gather eight
single\-precision floating\-point values. For qword indices, the
instruction will gather four values and zero the upper 128 bits of the
destination.

.PP
Note that:

.RS
.IP \(bu 2
If any pair of the index, mask, or destination registers are the
same, this instruction results a UD fault.
.IP \(bu 2
The values may be read from memory in any order. Memory ordering
with other instructions follows the Intel\-64 memory\-ordering model.
.IP \(bu 2
Faults are delivered in a right\-to\-left manner. That is, if a fault
is triggered by an element and delivered, all elements closer to the
LSB of the destination will be completed (and non\-faulting).
Individual elements closer to the MSB may or may not be completed.
If a given element triggers multiple faults, they are delivered in
the conventional order.
.IP \(bu 2
Elements may be gathered in any order, but faults must be delivered
in a right\-to\-left order; thus, elements to the left of a faulting
one may be gathered before the fault is delivered. A given
implementation of this instruction is repeatable \- given the same
input values and architectural state, the same set of elements to
the left of the faulting one will be gathered.
.IP \(bu 2
This instruction does not perform AC checks, and so will never
deliver an AC fault.
.IP \(bu 2
This instruction will cause a #UD if the address size attribute is
16\-bit.
.IP \(bu 2
This instruction will cause a #UD if the memory operand is encoded
without the SIB byte.
.IP \(bu 2
This instruction should not be used to access memory mapped I/O as
the ordering of the individual loads it does is implementation
specific, and some implementations may use loads larger than the
data element size or load elements an indeterminate number of times.
.IP \(bu 2
The scaled index may require more bits to represent than the address
bits used by the processor (e.g., in 32\-bit mode, if the scale is
greater than one). In this case, the most significant bits beyond
the number of address bits are ignored.

.RE

.SH OPERATION
.PP
.RS

.nf
DEST ← SRC1;
BASE\_ADDR: base register encoded in VSIB addressing;
VINDEX: the vector index register encoded by VSIB addressing;
SCALE: scale factor encoded by SIB:[7:6];
DISP: optional 1, 4 byte displacement;
MASK ← SRC3;

.fi
.RE

.SS VGATHERDPS (VEX.128 version)
.PP
.RS

.nf
MASK[MAXVL\-1:128] ← 0;
FOR j←0 to 3
    i←j * 32;
    IF MASK[31+i] THEN
        MASK[i +31:i]←FFFFFFFFH; // extend from most significant bit
    ELSE
        MASK[i +31:i]←0;
    FI;
ENDFOR
FOR j←0 to 3
    i←j * 32;
    DATA\_ADDR←BASE\_ADDR + (SignExtend(VINDEX[i+31:i])*SCALE + DISP;
    IF MASK[31+i] THEN
        DEST[i +31:i]←FETCH\_32BITS(DATA\_ADDR); // a fault exits the instruction
    FI;
    MASK[i +31:i]←0;
ENDFOR
DEST[MAXVL\-1:128] ← 0;

.fi
.RE

.SS VGATHERQPS (VEX.128 version)
.PP
.RS

.nf
MASK[MAXVL\-1:64] ← 0;
FOR j←0 to 3
    i←j * 32;
    IF MASK[31+i] THEN
        MASK[i +31:i]←FFFFFFFFH; // extend from most significant bit
    ELSE
        MASK[i +31:i]←0;
    FI;
ENDFOR
FOR j←0 to 1
    k←j * 64;
    i←j * 32;
    DATA\_ADDR←BASE\_ADDR + (SignExtend(VINDEX1[k+63:k])*SCALE + DISP;
    IF MASK[31+i] THEN
        DEST[i +31:i]←FETCH\_32BITS(DATA\_ADDR); // a fault exits the instruction
    FI;
    MASK[i +31:i]←0;
ENDFOR
DEST[MAXVL\-1:64] ← 0;

.fi
.RE

.SS VGATHERDPS (VEX.256 version)
.PP
.RS

.nf
MASK[MAXVL\-1:256] ← 0;
FOR j←0 to 7
    i←j * 32;
    IF MASK[31+i] THEN
        MASK[i +31:i]←FFFFFFFFH; // extend from most significant bit
    ELSE
        MASK[i +31:i]←0;
    FI;
ENDFOR
FOR j←0 to 7
    i←j * 32;
    DATA\_ADDR←BASE\_ADDR + (SignExtend(VINDEX1[i+31:i])*SCALE + DISP;
    IF MASK[31+i] THEN
        DEST[i +31:i]←FETCH\_32BITS(DATA\_ADDR); // a fault exits the instruction
    FI;
    MASK[i +31:i]←0;
ENDFOR
DEST[MAXVL\-1:256] ← 0;

.fi
.RE

.SS VGATHERQPS (VEX.256 version)
.PP
.RS

.nf
MASK[MAXVL\-1:128] ← 0;
FOR j←0 to 7
    i←j * 32;
    IF MASK[31+i] THEN
        MASK[i +31:i]←FFFFFFFFH; // extend from most significant bit
    ELSE
        MASK[i +31:i]←0;
    FI;
ENDFOR
FOR j←0 to 3
    k←j * 64;
    i←j * 32;
    DATA\_ADDR←BASE\_ADDR + (SignExtend(VINDEX1[k+63:k])*SCALE + DISP;
    IF MASK[31+i] THEN
        DEST[i +31:i]←FETCH\_32BITS(DATA\_ADDR); // a fault exits the instruction
    FI;
    MASK[i +31:i]←0;
ENDFOR
DEST[MAXVL\-1:128] ← 0;

.fi
.RE

.SH INTEL C/C++ COMPILER INTRINSIC EQUIVALENT
.PP
.RS

.nf
VGATHERDPS: \_\_m128 \_mm\_i32gather\_ps (float const * base, \_\_m128i index, const int scale);

VGATHERDPS: \_\_m128 \_mm\_mask\_i32gather\_ps (\_\_m128 src, float const * base, \_\_m128i index, \_\_m128 mask, const int scale);

VGATHERDPS: \_\_m256 \_mm256\_i32gather\_ps (float const * base, \_\_m256i index, const int scale);

VGATHERDPS: \_\_m256 \_mm256\_mask\_i32gather\_ps (\_\_m256 src, float const * base, \_\_m256i index, \_\_m256 mask, const int scale);

VGATHERQPS: \_\_m128 \_mm\_i64gather\_ps (float const * base, \_\_m128i index, const int scale);

VGATHERQPS: \_\_m128 \_mm\_mask\_i64gather\_ps (\_\_m128 src, float const * base, \_\_m128i index, \_\_m128 mask, const int scale);

VGATHERQPS: \_\_m128 \_mm256\_i64gather\_ps (float const * base, \_\_m256i index, const int scale);

VGATHERQPS: \_\_m128 \_mm256\_mask\_i64gather\_ps (\_\_m128 src, float const * base, \_\_m256i index, \_\_m128 mask, const int scale);

.fi
.RE

.SH SIMD FLOATING\-POINT EXCEPTIONS
.PP
None

.SH OTHER EXCEPTIONS
.PP
See Exceptions Type 12.

.SH SEE ALSO
.PP
x86\-manpages(7) for a list of other x86\-64 man pages.

.SH COLOPHON
.PP
This UNOFFICIAL, mechanically\-separated, non\-verified reference is
provided for convenience, but it may be incomplete or broken in
various obvious or non\-obvious ways. Refer to Intel® 64 and IA\-32
Architectures Software Developer’s Manual for anything serious.

.br
This page is generated by scripts; therefore may contain visual or semantical bugs. Please report them (or better, fix them) on https://github.com/ttmo-O/x86-manpages.

.br
MIT licensed by TTMO 2020 (Turkish Unofficial Chamber of Reverse Engineers - https://ttmo.re).
