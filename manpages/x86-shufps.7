.nh
.TH "X86-SHUFPS" "7" "May 2019" "TTMO" "Intel x86-64 ISA Manual"
.SH NAME
SHUFPS - PACKED INTERLEAVE SHUFFLE OF QUADRUPLETS OF SINGLE-PRECISION FLOATING-POINT VALUES
.TS
allbox;
l l l l l 
l l l l l .
\fB\fCOpcode/Instruction\fR	\fB\fCOp / En\fR	\fB\fC64/32 bit Mode Support\fR	\fB\fCCPUID Feature Flag\fR	\fB\fCDescription\fR
T{
NP 0F C6 /r ib SHUFPS xmm1, xmm3/m128, imm8
T}
	A	V/V	SSE	T{
Select from quadruplet of single\-precision floating\-point values in xmm1 and xmm2/m128 using imm8, interleaved result pairs are stored in xmm1.
T}
T{
VEX.128.0F.WIG C6 /r ib VSHUFPS xmm1, xmm2, xmm3/m128, imm8
T}
	B	V/V	AVX	T{
Select from quadruplet of single\-precision floating\-point values in xmm1 and xmm2/m128 using imm8, interleaved result pairs are stored in xmm1.
T}
T{
VEX.256.0F.WIG C6 /r ib VSHUFPS ymm1, ymm2, ymm3/m256, imm8
T}
	B	V/V	AVX	T{
Select from quadruplet of single\-precision floating\-point values in ymm2 and ymm3/m256 using imm8, interleaved result pairs are stored in ymm1.
T}
T{
EVEX.128.0F.W0 C6 /r ib VSHUFPS xmm1{k1}{z}, xmm2, xmm3/m128/m32bcst, imm8
T}
	C	V/V	AVX512VL AVX512F	T{
Select from quadruplet of single\-precision floating\-point values in xmm1 and xmm2/m128 using imm8, interleaved result pairs are stored in xmm1, subject to writemask k1.
T}
T{
EVEX.256.0F.W0 C6 /r ib VSHUFPS ymm1{k1}{z}, ymm2, ymm3/m256/m32bcst, imm8
T}
	C	V/V	AVX512VL AVX512F	T{
Select from quadruplet of single\-precision floating\-point values in ymm2 and ymm3/m256 using imm8, interleaved result pairs are stored in ymm1, subject to writemask k1.
T}
T{
EVEX.512.0F.W0 C6 /r ib VSHUFPS zmm1{k1}{z}, zmm2, zmm3/m512/m32bcst, imm8
T}
	C	V/V	AVX512F	T{
Select from quadruplet of single\-precision floating\-point values in zmm2 and zmm3/m512 using imm8, interleaved result pairs are stored in zmm1, subject to writemask k1.
T}
.TE

.SH INSTRUCTION OPERAND ENCODING
.TS
allbox;
l l l l l l 
l l l l l l .
Op/En	Tuple Type	Operand 1	Operand 2	Operand 3	Operand 4
A	NA	ModRM:reg (r, w)	ModRM:r/m (r)	Imm8	NA
B	NA	ModRM:reg (w)	VEX.vvvv (r)	ModRM:r/m (r)	Imm8
C	Full	ModRM:reg (w)	EVEX.vvvv (r)	ModRM:r/m (r)	Imm8
.TE

.SS Description
.PP
Selects a single\-precision floating\-point value of an input quadruplet
using a two\-bit control and move to a designated element of the
destination operand. Each 64\-bit element\-pair of a 128\-bit lane of the
destination operand is interleaved between the corresponding lane of the
first source operand and the second source operand at the granularity
128 bits. Each two bits in the imm8 byte, starting from bit 0, is the
select control of the corresponding element of a 128\-bit lane of the
destination to received the shuffled result of an input quadruplet. The
two lower elements of a 128\-bit lane in the destination receives shuffle
results from the quadruple of the first source operand. The next two
elements of the destination receives shuffle results from the quadruple
of the second source operand.

.PP
EVEX encoded versions: The first source operand is a ZMM/YMM/XMM
register. The second source operand can be a ZMM/YMM/XMM register, a
512/256/128\-bit memory location or a 512/256/128\-bit vector broadcasted
from a 32\-bit memory location. The destination operand is a ZMM/YMM/XMM
register updated according to the writemask. Imm8[7:0] provides 4
select controls for each applicable 128\-bit lane of the destination.

.PP
VEX.256 encoded version: The first source operand is a YMM register. The
second source operand can be a YMM register or a 256\-bit memory
location. The destination operand is a YMM register. Imm8[7:0]
provides 4 select controls for the high and low 128\-bit of the
destination.

.PP
VEX.128 encoded version: The first source operand is a XMM register. The
second source operand can be a XMM register or a 128\-bit memory
location. The destination operand is a XMM register. The upper bits
(MAXVL\-1:128) of the corresponding ZMM register destination are zeroed.
Imm8[7:0] provides 4 select controls for each element of the
destination.

.PP
128\-bit Legacy SSE version: The source can be an XMM register or an
128\-bit memory location. The destination is not distinct from the first
source XMM register and the upper bits (MAXVL\-1:128) of the
corresponding ZMM register destination are unmodified. Imm8[7:0]
provides 4 select controls for each element of the destination.

.PP
X7X6X5X4X3X2X1X0SRC1Y7Y6Y5Y4Y3Y2Y1Y0SRC2Y3 ..Y0Y3 ..Y0DESTY7 .. Y4Y7 ..
Y4X7 .. X4X7 .. X4X3 .. X0X3 .. X0

.PP
Figure 4\-26. 256\-bit VSHUFPS Operation of Selection from Input
Quadruplet and Pair\-wise Interleaved Result

.SS Operation
.PP
.RS

.nf
Select4(SRC, control) {
CASE (control[1:0]) OF
    0: TMP ←SRC[31:0];
    1: TMP ←SRC[63:32];
    2: TMP ←SRC[95:64];
    3: TMP ←SRC[127:96];
ESAC;
RETURN TMP
}

.fi
.RE

.SS VPSHUFPS (EVEX encoded versions when SRC2 is a vector register)
.PP
.RS

.nf
(KL, VL) = (4, 128), (8, 256), (16, 512)
TMP\_DEST[31:0]←Select4(SRC1[127:0], imm8[1:0]);
TMP\_DEST[63:32]←Select4(SRC1[127:0], imm8[3:2]);
TMP\_DEST[95:64]←Select4(SRC2[127:0], imm8[5:4]);
TMP\_DEST[127:96]←Select4(SRC2[127:0], imm8[7:6]);
IF VL >= 256
    TMP\_DEST[159:128]←Select4(SRC1[255:128], imm8[1:0]);
    TMP\_DEST[191:160]←Select4(SRC1[255:128], imm8[3:2]);
    TMP\_DEST[223:192]←Select4(SRC2[255:128], imm8[5:4]);
    TMP\_DEST[255:224]←Select4(SRC2[255:128], imm8[7:6]);
FI;
IF VL >= 512
    TMP\_DEST[287:256]←Select4(SRC1[383:256], imm8[1:0]);
    TMP\_DEST[319:288]←Select4(SRC1[383:256], imm8[3:2]);
    TMP\_DEST[351:320]←Select4(SRC2[383:256], imm8[5:4]);
    TMP\_DEST[383:352]←Select4(SRC2[383:256], imm8[7:6]);
    TMP\_DEST[415:384]←Select4(SRC1[511:384], imm8[1:0]);
    TMP\_DEST[447:416]←Select4(SRC1[511:384], imm8[3:2]);
    TMP\_DEST[479:448]←Select4(SRC2[511:384], imm8[5:4]);
    TMP\_DEST[511:480]←Select4(SRC2[511:384], imm8[7:6]);
FI;
FOR j←0 TO KL\-1
    i←j * 32
    IF k1[j] OR *no writemask*
        THEN DEST[i+31:i]←TMP\_DEST[i+31:i]
        ELSE
            IF *merging\-masking*
                        ; merging\-masking
                THEN *DEST[i+31:i] remains unchanged*
                ELSE *zeroing\-masking*
                            ; zeroing\-masking
                    DEST[i+31:i] ← 0
            FI
    FI;
ENDFOR
DEST[MAXVL\-1:VL] ← 0

.fi
.RE

.SS VPSHUFPS (EVEX encoded versions when SRC2 is memory)
.PP
.RS

.nf
(KL, VL) = (4, 128), (8, 256), (16, 512)
FOR j←0 TO KL\-1
    i←j * 32
    IF (EVEX.b = 1)
        THEN TMP\_SRC2[i+31:i]←SRC2[31:0]
        ELSE TMP\_SRC2[i+31:i]←SRC2[i+31:i]
    FI;
ENDFOR;
TMP\_DEST[31:0]←Select4(SRC1[127:0], imm8[1:0]);
TMP\_DEST[63:32]←Select4(SRC1[127:0], imm8[3:2]);
TMP\_DEST[95:64]←Select4(TMP\_SRC2[127:0], imm8[5:4]);
TMP\_DEST[127:96]←Select4(TMP\_SRC2[127:0], imm8[7:6]);
IF VL >= 256
    TMP\_DEST[159:128]←Select4(SRC1[255:128], imm8[1:0]);
    TMP\_DEST[191:160]←Select4(SRC1[255:128], imm8[3:2]);
    TMP\_DEST[223:192]←Select4(TMP\_SRC2[255:128], imm8[5:4]);
    TMP\_DEST[255:224]←Select4(TMP\_SRC2[255:128], imm8[7:6]);
FI;
IF VL >= 512
    TMP\_DEST[287:256]←Select4(SRC1[383:256], imm8[1:0]);
    TMP\_DEST[319:288]←Select4(SRC1[383:256], imm8[3:2]);
    TMP\_DEST[351:320]←Select4(TMP\_SRC2[383:256], imm8[5:4]);
    TMP\_DEST[383:352]←Select4(TMP\_SRC2[383:256], imm8[7:6]);
    TMP\_DEST[415:384]←Select4(SRC1[511:384], imm8[1:0]);
    TMP\_DEST[447:416]←Select4(SRC1[511:384], imm8[3:2]);
    TMP\_DEST[479:448]←Select4(TMP\_SRC2[511:384], imm8[5:4]);
    TMP\_DEST[511:480]←Select4(TMP\_SRC2[511:384], imm8[7:6]);
FI;
FOR j←0 TO KL\-1
    i←j * 32
    IF k1[j] OR *no writemask*
        THEN DEST[i+31:i]←TMP\_DEST[i+31:i]
        ELSE
            IF *merging\-masking*
                        ; merging\-masking
                THEN *DEST[i+31:i] remains unchanged*
                ELSE *zeroing\-masking*
                            ; zeroing\-masking
                    DEST[i+31:i] ← 0
            FI
    FI;
ENDFOR
DEST[MAXVL\-1:VL] ← 0

.fi
.RE

.SS VSHUFPS (VEX.256 encoded version)
.PP
.RS

.nf
DEST[31:0]←Select4(SRC1[127:0], imm8[1:0]);
DEST[63:32]←Select4(SRC1[127:0], imm8[3:2]);
DEST[95:64]←Select4(SRC2[127:0], imm8[5:4]);
DEST[127:96]←Select4(SRC2[127:0], imm8[7:6]);
DEST[159:128]←Select4(SRC1[255:128], imm8[1:0]);
DEST[191:160]←Select4(SRC1[255:128], imm8[3:2]);
DEST[223:192]←Select4(SRC2[255:128], imm8[5:4]);
DEST[255:224]←Select4(SRC2[255:128], imm8[7:6]);
DEST[MAXVL\-1:256] ←0

.fi
.RE

.SS VSHUFPS (VEX.128 encoded version)
.PP
.RS

.nf
DEST[31:0]←Select4(SRC1[127:0], imm8[1:0]);
DEST[63:32]←Select4(SRC1[127:0], imm8[3:2]);
DEST[95:64]←Select4(SRC2[127:0], imm8[5:4]);
DEST[127:96]←Select4(SRC2[127:0], imm8[7:6]);
DEST[MAXVL\-1:128] ←0

.fi
.RE

.SS SHUFPS (128\-bit Legacy SSE version)
.PP
.RS

.nf
DEST[31:0]←Select4(SRC1[127:0], imm8[1:0]);
DEST[63:32]←Select4(SRC1[127:0], imm8[3:2]);
DEST[95:64]←Select4(SRC2[127:0], imm8[5:4]);
DEST[127:96]←Select4(SRC2[127:0], imm8[7:6]);
DEST[MAXVL\-1:128] (Unmodified)

.fi
.RE

.SS Intel C/C++ Compiler Intrinsic Equivalent
.PP
.RS

.nf
VSHUFPS \_\_m512 \_mm512\_shuffle\_ps(\_\_m512 a, \_\_m512 b, int imm);

VSHUFPS \_\_m512 \_mm512\_mask\_shuffle\_ps(\_\_m512 s, \_\_mmask16 k, \_\_m512 a, \_\_m512 b, int imm);

VSHUFPS \_\_m512 \_mm512\_maskz\_shuffle\_ps(\_\_mmask16 k, \_\_m512 a, \_\_m512 b, int imm);

VSHUFPS \_\_m256 \_mm256\_shuffle\_ps (\_\_m256 a, \_\_m256 b, const int select);

VSHUFPS \_\_m256 \_mm256\_mask\_shuffle\_ps(\_\_m256 s, \_\_mmask8 k, \_\_m256 a, \_\_m256 b, int imm);

VSHUFPS \_\_m256 \_mm256\_maskz\_shuffle\_ps(\_\_mmask8 k, \_\_m256 a, \_\_m256 b, int imm);

SHUFPS \_\_m128 \_mm\_shuffle\_ps (\_\_m128 a, \_\_m128 b, const int select);

VSHUFPS \_\_m128 \_mm\_mask\_shuffle\_ps(\_\_m128 s, \_\_mmask8 k, \_\_m128 a, \_\_m128 b, int imm);

VSHUFPS \_\_m128 \_mm\_maskz\_shuffle\_ps(\_\_mmask8 k, \_\_m128 a, \_\_m128 b, int imm);

.fi
.RE

.SS SIMD Floating\-Point Exceptions
.PP
None

.SS Other Exceptions
.PP
Non\-EVEX\-encoded instruction, see Exceptions Type 4.

.PP
EVEX\-encoded instruction, see Exceptions Type E4NF.

.SH SEE ALSO
.PP
x86\-manpages(7) for a list of other x86\-64 man pages.

.SH COLOPHON
.PP
This UNOFFICIAL, mechanically\-separated, non\-verified reference is
provided for convenience, but it may be incomplete or broken in
various obvious or non\-obvious ways. Refer to Intel® 64 and IA\-32
Architectures Software Developer’s Manual for anything serious.

.br
This page is generated by scripts; therefore may contain visual or semantical bugs. Please report them (or better, fix them) on https://github.com/ttmo-O/x86-manpages.

.br
MIT licensed by TTMO 2020 (Turkish Unofficial Chamber of Reverse Engineers - https://ttmo.re).
