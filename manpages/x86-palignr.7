.nh
.TH "X86-PALIGNR" "7" "May 2019" "TTMO" "Intel x86-64 ISA Manual"
.SH NAME
PALIGNR - PACKED ALIGN RIGHT
.TS
allbox;
l l l l l 
l l l l l .
\fB\fCOpcode/Instruction\fR	\fB\fCOp/En\fR	\fB\fC64/32 bit Mode Support\fR	\fB\fCCPUID Feature Flag\fR	\fB\fCDescription\fR
T{
NP 0F 3A 0F /r ib1 PALIGNR mm1, mm2/m64, imm8
T}
	A	V/V	SSSE3	T{
Concatenate destination and source operands, extract byte\-aligned result shifted to the right by constant value in mm1.
T}
T{
66 0F 3A 0F /r ib PALIGNR xmm1, xmm2/m128, imm8
T}
	A	V/V	SSSE3	T{
Concatenate destination and source operands, extract byte\-aligned result shifted to the right by constant value in xmm1.
T}
T{
VEX.128.66.0F3A.WIG 0F /r ib VPALIGNR xmm1, xmm2, xmm3/m128, imm8
T}
	B	V/V	AVX	Concatenate xmm1.
T{
VEX.256.66.0F3A.WIG 0F /r ib VPALIGNR ymm1, ymm2, ymm3/m256, imm8
T}
	B	V/V	AVX2	T{
Concatenate pairs of 16 bytes in ymm2 and ymm1.
T}
T{
EVEX.128.66.0F3A.WIG 0F /r ib VPALIGNR xmm1 {k1}{z}, xmm2, xmm3/m128, imm8
T}
	C	V/V	AVX512VL AVX512BW	T{
Concatenate xmm2 and xmm3/m128 into a 32\-byte intermediate result, extract byte aligned result shifted to the right by constant value in imm8 and result is stored in xmm1.
T}
T{
EVEX.256.66.0F3A.WIG 0F /r ib VPALIGNR ymm1 {k1}{z}, ymm2, ymm3/m256, imm8
T}
	C	V/V	AVX512VL AVX512BW	T{
Concatenate pairs of 16 bytes in ymm2 and ymm3/m256 into 32\-byte intermediate result, extract byte\-aligned, 16\-byte result shifted to the right by constant values in imm8 from each intermediate result, and two 16\-byte results are stored in ymm1.
T}
T{
EVEX.512.66.0F3A.WIG 0F /r ib VPALIGNR zmm1 {k1}{z}, zmm2, zmm3/m512, imm8
T}
	C	V/V	AVX512BW	T{
Concatenate pairs of 16 bytes in zmm2 and zmm3/m512 into 32\-byte intermediate result, extract byte\-aligned, 16\-byte result shifted to the right by constant values in imm8 from each intermediate result, and four 16\-byte results are stored in zmm1.
T}
.TE

.PP
.RS

.PP
1\&. See note in Section 2.4, “AVX and SSE Instruction Exception
Specification” in the Intel® 64 and IA\-32 Architectures Software
Developer’s Manual, Volume 3A.

.RE

.SH INSTRUCTION OPERAND ENCODING
.TS
allbox;
l l l l l l 
l l l l l l .
Op/En	Tuple Type	Operand 1	Operand 2	Operand 3	Operand 4
A	NA	ModRM:reg (r, w)	ModRM:r/m (r)	imm8	NA
B	NA	ModRM:reg (w)	VEX.vvvv (r)	ModRM:r/m (r)	imm8
C	Full Mem	ModRM:reg (w)	EVEX.vvvv (r)	ModRM:r/m (r)	imm8
.TE

.SH DESCRIPTION
.PP
(V)PALIGNR concatenates the destination operand (the first operand) and
the source operand (the second operand) into an intermediate composite,
shifts the composite at byte granularity to the right by a constant
immediate, and extracts the right\-aligned result into the destination.
The first and the second operands can be an MMX,

.PP
XMM or a YMM register. The immediate value is considered unsigned.
Immediate shift counts larger than the 2L (i.e. 32 for 128\-bit operands,
or 16 for 64\-bit operands) produce a zero result. Both operands can be
MMX registers, XMM registers or YMM registers. When the source operand
is a 128\-bit memory operand, the operand must be aligned on a 16\-byte
boundary or a general\-protection exception (#GP) will be generated.

.PP
In 64\-bit mode and not encoded by VEX/EVEX prefix, use the REX prefix to
access additional registers.

.PP
128\-bit Legacy SSE version: Bits (MAXVL\-1:128) of the corresponding YMM
destination register remain unchanged.

.PP
EVEX.512 encoded version: The first source operand is a ZMM register and
contains four 16\-byte blocks. The second source operand is a ZMM
register or a 512\-bit memory location containing four 16\-byte block. The
destination operand is a ZMM register and contain four 16\-byte results.
The imm8[7:0] is the common shift count

.PP
used for each of the four successive 16\-byte block sources. The low
16\-byte block of the two source operands produce the low 16\-byte result
of the destination operand, the high 16\-byte block of the two source
operands produce the high 16\-byte result of the destination operand and
so on for the blocks in the middle.

.PP
VEX.256 and EVEX.256 encoded versions: The first source operand is a YMM
register and contains two 16\-byte blocks. The second source operand is a
YMM register or a 256\-bit memory location containing two 16\-byte block.
The destination operand is a YMM register and contain two 16\-byte
results. The imm8[7:0] is the common shift count used for the two
lower 16\-byte block sources and the two upper 16\-byte block sources. The
low 16\-byte block of the two source operands produce the low 16\-byte
result of the destination operand, the high 16\-byte block of the two
source operands produce the high 16\-byte result of the destination
operand. The upper bits (MAXVL\-1:256) of the corresponding ZMM register
destination are zeroed.

.PP
VEX.128 and EVEX.128 encoded versions: The first source operand is an
XMM register. The second source operand is an XMM register or 128\-bit
memory location. The destination operand is an XMM register. The upper
bits (MAXVL\-1:128) of the corresponding ZMM register destination are
zeroed.

.PP
Concatenation is done with 128\-bit data in the first and second source
operand for both 128\-bit and 256\-bit instructions. The high 128\-bits of
the intermediate composite 256\-bit result came from the 128\-bit data
from the first source operand; the low 128\-bits of the intermediate
result came from the 128\-bit data of the second source operand.

.PP
Note: VEX.L must be 0, otherwise the instruction will #UD.

.PP
0 127 0 127

.PP
SRC1SRC2Imm8[7:0]*8128 255128255SRC1SRC2Imm8[7:0]*8128
1270255DESTDEST

.PP
Figure 4\-7. 256\-bit VPALIGN Instruction Operation

.SH OPERATION
.SS PALIGNR (with 64\-bit operands)
.PP
.RS

.nf
temp1[127:0] = CONCATENATE(DEST,SRC)>>(imm8*8)
DEST[63:0] = temp1[63:0]

.fi
.RE

.SS PALIGNR (with 128\-bit operands)
.PP
.RS

.nf
temp1[255:0]←((DEST[127:0] << 128) OR SRC[127:0])>>(imm8*8);
DEST[127:0] ← temp1[127:0]
DEST[MAXVL\-1:128] (Unmodified)

.fi
.RE

.SS VPALIGNR (VEX.128 encoded version)
.PP
.RS

.nf
temp1[255:0]←((SRC1[127:0] << 128) OR SRC2[127:0])>>(imm8*8);
DEST[127:0] ← temp1[127:0]
DEST[MAXVL\-1:128] ← 0

.fi
.RE

.SS VPALIGNR (VEX.256 encoded version)
.PP
.RS

.nf
temp1[255:0]←((SRC1[127:0] << 128) OR SRC2[127:0])>>(imm8[7:0]*8);
DEST[127:0] ← temp1[127:0]
temp1[255:0]←((SRC1[255:128] << 128) OR SRC2[255:128])>>(imm8[7:0]*8);
DEST[MAXVL\-1:128] ← temp1[127:0]

.fi
.RE

.SS VPALIGNR (EVEX encoded versions)
.PP
.RS

.nf
(KL, VL) = (16, 128), (32, 256), (64, 512)
FOR l←0 TO VL\-1 with increments of 128
    temp1[255:0] ← ((SRC1[l+127:l] << 128) OR SRC2[l+127:l])>>(imm8[7:0]*8);
    TMP\_DEST[l+127:l] ← temp1[127:0]
ENDFOR;
FOR j←0 TO KL\-1
    i←j * 8
    IF k1[j] OR *no writemask*
        THEN DEST[i+7:i]←TMP\_DEST[i+7:i]
        ELSE
            IF *merging\-masking*
                        ; merging\-masking
                THEN *DEST[i+7:i] remains unchanged*
                ELSE *zeroing\-masking*
                            ; zeroing\-masking
                    DEST[i+7:i] = 0
            FI
    FI;
ENDFOR;
DEST[MAXVL\-1:VL] ← 0

.fi
.RE

.SH INTEL C/C++ COMPILER INTRINSIC EQUIVALENTS
.PP
.RS

.nf
PALIGNR: \_\_m64 \_mm\_alignr\_pi8 (\_\_m64 a, \_\_m64 b, int n)

(V)PALIGNR: \_\_m128i \_mm\_alignr\_epi8 (\_\_m128i a, \_\_m128i b, int n)

VPALIGNR: VPALIGNR \_\_m512i \_mm512\_alignr\_epi8 (\_\_m512i a, \_\_m512i b, const int n)

VPALIGNR \_\_m512i \_mm512\_mask\_alignr\_epi8 (\_\_m512i s, \_\_mmask64 m, \_\_m512i a, \_\_m512i b, const int n)

VPALIGNR \_\_m512i \_mm512\_maskz\_alignr\_epi8 ( \_\_mmask64 m, \_\_m512i a, \_\_m512i b, const int n)

VPALIGNR \_\_m256i \_mm256\_mask\_alignr\_epi8 (\_\_m256i s, \_\_mmask32 m, \_\_m256i a, \_\_m256i b, const int n)

VPALIGNR \_\_m256i \_mm256\_maskz\_alignr\_epi8 (\_\_mmask32 m, \_\_m256i a, \_\_m256i b, const int n)

VPALIGNR \_\_m128i \_mm\_mask\_alignr\_epi8 (\_\_m128i s, \_\_mmask16 m, \_\_m128i a, \_\_m128i b, const int n)

VPALIGNR \_\_m128i \_mm\_maskz\_alignr\_epi8 (\_\_mmask16 m, \_\_m128i a, \_\_m128i b, const int n)

.fi
.RE

.SH SIMD FLOATING\-POINT EXCEPTIONS
.PP
None.

.SH OTHER EXCEPTIONS
.PP
Non\-EVEX\-encoded instruction, see Exceptions Type 4.

.PP
EVEX\-encoded instruction, see Exceptions Type E4NF.nb.

.SH SEE ALSO
.PP
x86\-manpages(7) for a list of other x86\-64 man pages.

.SH COLOPHON
.PP
This UNOFFICIAL, mechanically\-separated, non\-verified reference is
provided for convenience, but it may be incomplete or broken in
various obvious or non\-obvious ways. Refer to Intel® 64 and IA\-32
Architectures Software Developer’s Manual for anything serious.

.br
This page is generated by scripts; therefore may contain visual or semantical bugs. Please report them (or better, fix them) on https://github.com/ttmo-O/x86-manpages.

.br
MIT licensed by TTMO 2020 (Turkish Unofficial Chamber of Reverse Engineers - https://ttmo.re).
