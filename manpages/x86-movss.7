.nh
.TH "X86-MOVSS" "7" "May 2019" "TTMO" "Intel x86-64 ISA Manual"
.SH NAME
MOVSS - MOVE OR MERGE SCALAR SINGLE-PRECISION FLOATING-POINT VALUE
.TS
allbox;
l l l l l 
l l l l l .
\fB\fCOpcode/Instruction\fR	\fB\fCOp / En\fR	\fB\fC64/32 bit Mode Support\fR	\fB\fCCPUID Feature Flag\fR	\fB\fCDescription\fR
F3 0F 10 /r MOVSS xmm1, xmm2	A	V/V	SSE	T{
Merge scalar single\-precision floating\-point value from xmm2 to xmm1 register.
T}
F3 0F 10 /r MOVSS xmm1, m32	A	V/V	SSE	T{
Load scalar single\-precision floating\-point value from m32 to xmm1 register.
T}
T{
VEX.LIG.F3.0F.WIG 10 /r VMOVSS xmm1, xmm2, xmm3
T}
	B	V/V	AVX	T{
Merge scalar single\-precision floating\-point value from xmm2 and xmm3 to xmm1 register
T}
T{
VEX.LIG.F3.0F.WIG 10 /r VMOVSS xmm1, m32
T}
	D	V/V	AVX	T{
Load scalar single\-precision floating\-point value from m32 to xmm1 register.
T}
T{
F3 0F 11 /r MOVSS xmm2/m32, xmm1
T}
	C	V/V	SSE	T{
Move scalar single\-precision floating\-point value from xmm1 register to xmm2/m32.
T}
T{
VEX.LIG.F3.0F.WIG 11 /r VMOVSS xmm1, xmm2, xmm3
T}
	E	V/V	AVX	T{
Move scalar single\-precision floating\-point value from xmm2 and xmm3 to xmm1 register.
T}
T{
VEX.LIG.F3.0F.WIG 11 /r VMOVSS m32, xmm1
T}
	C	V/V	AVX	T{
Move scalar single\-precision floating\-point value from xmm1 register to m32.
T}
T{
EVEX.LIG.F3.0F.W0 10 /r VMOVSS xmm1 {k1}{z}, xmm2, xmm3
T}
	B	V/V	AVX512F	T{
Move scalar single\-precision floating\-point value from xmm2 and xmm3 to xmm1 register under writemask k1.
T}
T{
EVEX.LIG.F3.0F.W0 10 /r VMOVSS xmm1 {k1}{z}, m32
T}
	F	V/V	AVX512F	T{
Move scalar single\-precision floating\-point values from m32 to xmm1 under writemask k1.
T}
T{
EVEX.LIG.F3.0F.W0 11 /r VMOVSS xmm1 {k1}{z}, xmm2, xmm3
T}
	E	V/V	AVX512F	T{
Move scalar single\-precision floating\-point value from xmm2 and xmm3 to xmm1 register under writemask k1.
T}
T{
EVEX.LIG.F3.0F.W0 11 /r VMOVSS m32 {k1}, xmm1
T}
	G	V/V	AVX512F	T{
Move scalar single\-precision floating\-point values from xmm1 to m32 under writemask k1.
T}
.TE

.SH INSTRUCTION OPERAND ENCODING
.TS
allbox;
l l l l l l 
l l l l l l .
Op/En	Tuple Type	Operand 1	Operand 2	Operand 3	Operand 4
A	NA	ModRM:reg (r, w)	ModRM:r/m (r)	NA	NA
B	NA	ModRM:reg (w)	VEX.vvvv (r)	ModRM:r/m (r)	NA
C	NA	ModRM:r/m (w)	ModRM:reg (r)	NA	NA
D	NA	ModRM:reg (w)	ModRM:r/m (r)	NA	NA
E	NA	ModRM:r/m (w)	vvvv (r)	ModRM:reg (r)	NA
F	Tuple1 Scalar	ModRM:reg (r, w)	ModRM:r/m (r)	NA	NA
G	Tuple1 Scalar	ModRM:r/m (w)	ModRM:reg (r)	NA	NA
.TE

.SS Description
.PP
Moves a scalar single\-precision floating\-point value from the source
operand (second operand) to the destination operand (first operand). The
source and destination operands can be XMM registers or 32\-bit memory
locations. This instruction can be used to move a single\-precision
floating\-point value to and from the low doubleword of an XMM register
and a 32\-bit memory location, or to move a single\-precision
floating\-point value between the low doublewords of two XMM registers.
The instruction cannot be used to transfer data between memory
locations.

.PP
Legacy version: When the source and destination operands are XMM
registers, bits (MAXVL\-1:32) of the corresponding destination register
are unmodified. When the source operand is a memory location and
destination operand is an XMM registers, Bits (127:32) of the
destination operand is cleared to all 0s, bits MAXVL:128 of the
destination operand remains unchanged.

.PP
VEX and EVEX encoded register\-register syntax: Moves a scalar
single\-precision floating\-point value from the second source operand
(the third operand) to the low doubleword element of the destination
operand (the first operand). Bits 127:32 of the destination operand are
copied from the first source operand (the second operand). Bits
(MAXVL\-1:128) of the corresponding destination register are zeroed.

.PP
VEX and EVEX encoded memory load syntax: When the source operand is a
memory location and destination operand is an XMM registers, bits
MAXVL:32 of the destination operand is cleared to all 0s.

.PP
EVEX encoded versions: The low doubleword of the destination is updated
according to the writemask.

.PP
Note: For memory store form instruction “VMOVSS m32, xmm1”, VEX.vvvv is
reserved and must be 1111b otherwise instruction will #UD. For memory
store form instruction “VMOVSS mv {k1}, xmm1”, EVEX.vvvv is reserved and
must be 1111b otherwise instruction will #UD.

.PP
Software should ensure VMOVSS is encoded with VEX.L=0. Encoding VMOVSS
with VEX.L=1 may encounter unpredictable behavior across different
processor generations.

.SS Operation
.SS VMOVSS (EVEX.LIG.F3.0F.W0 11 /r when the source operand is memory and the destination is an XMM register)
.PP
.RS

.nf
IF k1[0] or *no writemask*
    THEN DEST[31:0] ← SRC[31:0]
    ELSE
        IF *merging\-masking* ; merging\-masking
            THEN *DEST[31:0] remains unchanged*
            ELSE ; zeroing\-masking
                THEN DEST[31:0]←0
        FI;
FI;
DEST[MAXVL\-1:32] ← 0

.fi
.RE

.SS VMOVSS (EVEX.LIG.F3.0F.W0 10 /r when the source operand is an XMM register and the destination is memory)
.PP
.RS

.nf
IF k1[0] or *no writemask*
    THEN DEST[31:0] ← SRC[31:0]
    ELSE *DEST[31:0] remains unchanged* ; merging\-masking
FI;

.fi
.RE

.SS VMOVSS (EVEX.LIG.F3.0F.W0 10/11 /r where the source and destination are XMM registers)
.PP
.RS

.nf
IF k1[0] or *no writemask*
    THEN DEST[31:0] ← SRC2[31:0]
    ELSE
        IF *merging\-masking* ; merging\-masking
            THEN *DEST[31:0] remains unchanged*
            ELSE ; zeroing\-masking
                THEN DEST[31:0]←0
        FI;
FI;
DEST[127:32] ← SRC1[127:32]
DEST[MAXVL\-1:128] ← 0

.fi
.RE

.SS MOVSS (Legacy SSE version when the source and destination operands are both XMM registers)
.PP
.RS

.nf
DEST[31:0] ←SRC[31:0]
DEST[MAXVL\-1:32] (Unmodified)

.fi
.RE

.SS VMOVSS (VEX.128.F3.0F 11 /r where the destination is an XMM register)
.PP
.RS

.nf
DEST[31:0] ←SRC2[31:0]
DEST[127:32] ←SRC1[127:32]
DEST[MAXVL\-1:128] ←0

.fi
.RE

.SS VMOVSS (VEX.128.F3.0F 10 /r where the source and destination are XMM registers)
.PP
.RS

.nf
DEST[31:0] ←SRC2[31:0]
DEST[127:32] ←SRC1[127:32]
DEST[MAXVL\-1:128] ←0

.fi
.RE

.SS VMOVSS (VEX.128.F3.0F 10 /r when the source operand is memory and the destination is an XMM register)
.PP
.RS

.nf
DEST[31:0] ←SRC[31:0]
DEST[MAXVL\-1:32] ←0

.fi
.RE

.SS MOVSS/VMOVSS (when the source operand is an XMM register and the destination is memory)
.PP
.RS

.nf
DEST[31:0] ←SRC[31:0]

.fi
.RE

.SS MOVSS (Legacy SSE version when the source operand is memory and the destination is an XMM register)
.PP
.RS

.nf
DEST[31:0] ←SRC[31:0]
DEST[127:32] ←0
DEST[MAXVL\-1:128] (Unmodified)

.fi
.RE

.SS Intel C/C++ Compiler Intrinsic Equivalent
.PP
.RS

.nf
VMOVSS \_\_m128 \_mm\_mask\_load\_ss(\_\_m128 s, \_\_mmask8 k, float * p);

VMOVSS \_\_m128 \_mm\_maskz\_load\_ss( \_\_mmask8 k, float * p);

VMOVSS \_\_m128 \_mm\_mask\_move\_ss(\_\_m128 sh, \_\_mmask8 k, \_\_m128 sl, \_\_m128 a);

VMOVSS \_\_m128 \_mm\_maskz\_move\_ss( \_\_mmask8 k, \_\_m128 s, \_\_m128 a);

VMOVSS void \_mm\_mask\_store\_ss(float * p, \_\_mmask8 k, \_\_m128 a);

MOVSS \_\_m128 \_mm\_load\_ss(float * p)

MOVSS void\_mm\_store\_ss(float * p, \_\_m128 a)

MOVSS \_\_m128 \_mm\_move\_ss(\_\_m128 a, \_\_m128 b)

.fi
.RE

.SS SIMD Floating\-Point Exceptions
.PP
None

.SS Other Exceptions
.PP
Non\-EVEX\-encoded instruction, see Exceptions Type 5; additionally

.TS
allbox;
l l 
l l .
#UD	If VEX.vvvv != 1111B.
.TE

.PP
EVEX\-encoded instruction, see Exceptions Type E10.

.SH SEE ALSO
.PP
x86\-manpages(7) for a list of other x86\-64 man pages.

.SH COLOPHON
.PP
This UNOFFICIAL, mechanically\-separated, non\-verified reference is
provided for convenience, but it may be incomplete or broken in
various obvious or non\-obvious ways. Refer to Intel® 64 and IA\-32
Architectures Software Developer’s Manual for anything serious.

.br
This page is generated by scripts; therefore may contain visual or semantical bugs. Please report them (or better, fix them) on https://github.com/ttmo-O/x86-manpages.

.br
MIT licensed by TTMO 2020 (Turkish Unofficial Chamber of Reverse Engineers - https://ttmo.re).
