.nh
.TH "X86-PUNPCKHBW-PUNPCKHWD-PUNPCKHDQ-PUNPCKHQDQ" "7" "May 2019" "TTMO" "Intel x86-64 ISA Manual"
.SH NAME
PUNPCKHBW-PUNPCKHWD-PUNPCKHDQ-PUNPCKHQDQ - UNPACK HIGH DATA
.TS
allbox;
l l l l l 
l l l l l .
\fB\fCOpcode/Instruction\fR	\fB\fCOp/En\fR	\fB\fC64/32 bit Mode Support\fR	\fB\fCCPUID Feature Flag\fR	\fB\fCDescription\fR
NP 0F 68 /mm, mm/m64	A	V/V	MMX	T{
Unpack and interleave high\-order bytes from mm.
T}
66 0F 68 /xmm2/m128	A	V/V	SSE2	T{
Unpack and interleave high\-order bytes from xmm1.
T}
NP 0F 69 /mm, mm/m64	A	V/V	MMX	T{
Unpack and interleave high\-order words from mm.
T}
66 0F 69 /xmm2/m128	A	V/V	SSE2	T{
Unpack and interleave high\-order words from xmm1.
T}
NP 0F 6A /mm, mm/m64	A	V/V	MMX	T{
Unpack and interleave high\-order doublewords from mm.
T}
66 0F 6A /xmm2/m128	A	V/V	SSE2	T{
Unpack and interleave high\-order doublewords from xmm1.
T}
66 0F 6D /xmm2/m128	A	V/V	SSE2	T{
Unpack and interleave high\-order quadwords from xmm1.
T}
T{
VEX.128.66.0F.WIG 68/r VPUNPCKHBW xmm1,xmm2, xmm3/m128
T}
	B	V/V	AVX	T{
Interleave high\-order bytes from xmm1.
T}
T{
VEX.128.66.0F.WIG 69/r VPUNPCKHWD xmm1,xmm2, xmm3/m128
T}
	B	V/V	AVX	T{
Interleave high\-order words from xmm1.
T}
T{
VEX.128.66.0F.WIG 6A/r VPUNPCKHDQ xmm1, xmm2, xmm3/m128
T}
	B	V/V	AVX	T{
Interleave high\-order doublewords from xmm1.
T}
T{
VEX.128.66.0F.WIG 6D/r VPUNPCKHQDQ xmm1, xmm2, xmm3/m128
T}
	B	V/V	AVX	T{
Interleave high\-order quadword from xmm1 register.
T}
T{
VEX.256.66.0F.WIG 68 /r VPUNPCKHBW ymm1, ymm2, ymm3/m256
T}
	B	V/V	AVX2	T{
Interleave high\-order bytes from ymm1 register.
T}
T{
VEX.256.66.0F.WIG 69 /r VPUNPCKHWD ymm1, ymm2, ymm3/m256
T}
	B	V/V	AVX2	T{
Interleave high\-order words from ymm1 register.
T}
T{
VEX.256.66.0F.WIG 6A /r VPUNPCKHDQ ymm1, ymm2, ymm3/m256
T}
	B	V/V	AVX2	T{
Interleave high\-order doublewords from ymm1 register.
T}
T{
VEX.256.66.0F.WIG 6D /r VPUNPCKHQDQ ymm1, ymm2, ymm3/m256
T}
	B	V/V	AVX2	T{
Interleave high\-order quadword from ymm1 register.
T}
T{
EVEX.128.66.0F.WIG 68 /r VPUNPCKHBW xmm1 {k1}{z}, xmm2, xmm3/m128
T}
	C	V/V	AVX512VL AVX512BW	T{
Interleave high\-order bytes from xmm2 and xmm3/m128 into xmm1 register using k1 write mask.
T}
T{
EVEX.128.66.0F.WIG 69 /r VPUNPCKHWD xmm1 {k1}{z}, xmm2, xmm3/m128
T}
	C	V/V	AVX512VL AVX512BW	T{
Interleave high\-order words from xmm2 and xmm3/m128 into xmm1 register using k1 write mask.
T}
T{
EVEX.128.66.0F.W0 6A /r VPUNPCKHDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m32bcst
T}
	D	V/V	AVX512VL AVX512F	T{
Interleave high\-order doublewords from xmm2 and xmm3/m128/m32bcst into xmm1 register using k1 write mask.
T}
T{
EVEX.128.66.0F.W1 6D /r VPUNPCKHQDQ xmm1 {k1}{z}, xmm2, xmm3/m128/m64bcst
T}
	D	V/V	AVX512VL AVX512F	T{
Interleave high\-order quadword from xmm2 and xmm3/m128/m64bcst into xmm1 register using k1 write mask.
T}
.TE

.TS
allbox;
l l l l l 
l l l l l .
T{
EVEX.256.66.0F.WIG 68 /r VPUNPCKHBW ymm1 {k1}{z}, ymm2, ymm3/m256
T}
	C	V/V	AVX512VL AVX512BW	T{
Interleave high\-order bytes from ymm2 and ymm3/m256 into ymm1 register using k1 write mask.
T}
T{
EVEX.256.66.0F.WIG 69 /r VPUNPCKHWD ymm1 {k1}{z}, ymm2, ymm3/m256
T}
	C	V/V	AVX512VL AVX512BW	T{
Interleave high\-order words from ymm2 and ymm3/m256 into ymm1 register using k1 write mask.
T}
T{
EVEX.256.66.0F.W0 6A /r VPUNPCKHDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m32bcst
T}
	D	V/V	AVX512VL AVX512F	T{
Interleave high\-order doublewords from ymm2 and ymm3/m256/m32bcst into ymm1 register using k1 write mask.
T}
T{
EVEX.256.66.0F.W1 6D /r VPUNPCKHQDQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst
T}
	D	V/V	AVX512VL AVX512F	T{
Interleave high\-order quadword from ymm2 and ymm3/m256/m64bcst into ymm1 register using k1 write mask.
T}
T{
EVEX.512.66.0F.WIG 68/r VPUNPCKHBW zmm1 {k1}{z}, zmm2, zmm3/m512
T}
	C	V/V	AVX512BW	T{
Interleave high\-order bytes from zmm2 and zmm3/m512 into zmm1 register.
T}
T{
EVEX.512.66.0F.WIG 69/r VPUNPCKHWD zmm1 {k1}{z}, zmm2, zmm3/m512
T}
	C	V/V	AVX512BW	T{
Interleave high\-order words from zmm2 and zmm3/m512 into zmm1 register.
T}
T{
EVEX.512.66.0F.W0 6A /r VPUNPCKHDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m32bcst
T}
	D	V/V	AVX512F	T{
Interleave high\-order doublewords from zmm2 and zmm3/m512/m32bcst into zmm1 register using k1 write mask.
T}
T{
EVEX.512.66.0F.W1 6D /r VPUNPCKHQDQ zmm1 {k1}{z}, zmm2, zmm3/m512/m64bcst
T}
	D	V/V	AVX512F	T{
Interleave high\-order quadword from zmm2 and zmm3/m512/m64bcst into zmm1 register using k1 write mask.
T}
.TE

.PP
.RS

.PP
1\&. See note in Section 2.4, “AVX and SSE Instruction Exception
Specification” in the Intel® 64 and IA\-32 Architectures Software
Developer’s Manual, Volume 3A.

.RE

.SH INSTRUCTION OPERAND ENCODING
.TS
allbox;
l l l l l l 
l l l l l l .
Op/En	Tuple Type	Operand 1	Operand 2	Operand 3	Operand 4
A	NA	ModRM:reg (r, w)	ModRM:r/m (r)	NA	NA
B	NA	ModRM:reg (w)	VEX.vvvv (r)	ModRM:r/m (r)	NA
C	Full Mem	ModRM:reg (w)	EVEX.vvvv (r)	ModRM:r/m (r)	NA
D	Full	ModRM:reg (w)	EVEX.vvvv (r)	ModRM:r/m (r)	NA
.TE

.SH DESCRIPTION
.PP
Unpacks and interleaves the high\-order data elements (bytes, words,
doublewords, or quadwords) of the destination operand (first operand)
and source operand (second operand) into the destination operand. Figure
4\-20 shows the unpack operation for bytes in 64\-bit operands. The
low\-order data elements are ignored.

.PP
X7X6X5X4X3X2X1X0Y7Y6Y5Y4Y3Y2Y1SRCDESTY0Y7X7Y6X6Y5X5Y4X4DEST

.PP
Figure 4\-20. PUNPCKHBW Instruction Operation Using 64\-bit Operands

.PP
255 31 0 255 31 0

.PP
SRC2550DEST

.PP
Figure 4\-21. 256\-bit VPUNPCKHDQ Instruction Operation

.PP
When the source data comes from a 64\-bit memory operand, the full 64\-bit
operand is accessed from memory, but the instruction uses only the
high\-order 32 bits. When the source data comes from a 128\-bit memory
operand, an implementation may fetch only the appropriate 64 bits;
however, alignment to a 16\-byte boundary and normal segment checking
will still be enforced.

.PP
The (V)PUNPCKHBW instruction interleaves the high\-order bytes of the
source and destination operands, the (V)PUNPCKHWD instruction
interleaves the high\-order words of the source and destination operands,
the (V)PUNPCKHDQ instruction interleaves the high\-order doubleword (or
doublewords) of the source and destination operands, and the
(V)PUNPCKHQDQ instruction interleaves the high\-order quadwords of the
source and destination operands.

.PP
These instructions can be used to convert bytes to words, words to
doublewords, doublewords to quadwords, and quadwords to double
quadwords, respectively, by placing all 0s in the source operand. Here,
if the source operand contains all 0s, the result (stored in the
destination operand) contains zero extensions of the high\-order data
elements from the original value in the destination operand. For
example, with the (V)PUNPCKHBW instruction the high\-order bytes are zero
extended (that is, unpacked into unsigned word integers), and with the
(V)PUNPCKHWD instruction, the high\-order words are zero extended
(unpacked into unsigned doubleword integers).

.PP
In 64\-bit mode and not encoded with VEX/EVEX, using a REX prefix in the
form of REX.R permits this instruction to access additional registers
(XMM8\-XMM15).

.PP
Legacy SSE versions 64\-bit operand: The source operand can be an MMX
technology register or a 64\-bit memory location. The destination operand
is an MMX technology register.

.PP
128\-bit Legacy SSE versions: The second source operand is an XMM
register or a 128\-bit memory location. The first source operand and
destination operands are XMM registers. Bits (MAXVL\-1:128) of the
corresponding YMM destination register remain unchanged.

.PP
VEX.128 encoded versions: The second source operand is an XMM register
or a 128\-bit memory location. The first source operand and destination
operands are XMM registers. Bits (MAXVL\-1:128) of the destination YMM
register are zeroed.

.PP
VEX.256 encoded version: The second source operand is an YMM register or
an 256\-bit memory location. The first source operand and destination
operands are YMM registers.

.PP
EVEX encoded VPUNPCKHDQ/QDQ: The second source operand is a ZMM/YMM/XMM
register, a 512/256/128\-bit memory location or a 512/256/128\-bit vector
broadcasted from a 32/64\-bit memory location. The first source operand
and destination operands are ZMM/YMM/XMM registers. The destination is
conditionally updated with writemask k1.

.PP
EVEX encoded VPUNPCKHWD/BW: The second source operand is a ZMM/YMM/XMM
register, a 512/256/128\-bit memory location. The first source operand
and destination operands are ZMM/YMM/XMM registers. The destination is
conditionally updated with writemask k1.

.SH OPERATION
.SS PUNPCKHBW instruction with 64\-bit operands:
.PP
.RS

.nf
DEST[7:0] ← DEST[39:32];
DEST[15:8] ← SRC[39:32];
DEST[23:16] ← DEST[47:40];
DEST[31:24] ← SRC[47:40];
DEST[39:32] ← DEST[55:48];
DEST[47:40] ← SRC[55:48];
DEST[55:48] ← DEST[63:56];
DEST[63:56] ← SRC[63:56];

.fi
.RE

.SS PUNPCKHW instruction with 64\-bit operands:
.PP
.RS

.nf
DEST[15:0] ← DEST[47:32];
DEST[31:16] ← SRC[47:32];
DEST[47:32] ← DEST[63:48];
DEST[63:48] ← SRC[63:48];

.fi
.RE

.SS PUNPCKHDQ instruction with 64\-bit operands:
.PP
.RS

.nf
    DEST[31:0] ← DEST[63:32];
    DEST[63:32] ← SRC[63:32];
INTERLEAVE\_HIGH\_BYTES\_512b (SRC1, SRC2)
TMP\_DEST[255:0]←INTERLEAVE\_HIGH\_BYTES\_256b(SRC1[255:0], SRC[255:0])
TMP\_DEST[511:256]←INTERLEAVE\_HIGH\_BYTES\_256b(SRC1[511:256], SRC[511:256])
INTERLEAVE\_HIGH\_BYTES\_256b (SRC1, SRC2)
DEST[7:0] ← SRC1[71:64]
DEST[15:8] ← SRC2[71:64]
DEST[23:16] ← SRC1[79:72]
DEST[31:24] ← SRC2[79:72]
DEST[39:32] ← SRC1[87:80]
DEST[47:40] ← SRC2[87:80]
DEST[55:48] ← SRC1[95:88]
DEST[63:56] ← SRC2[95:88]
DEST[71:64] ← SRC1[103:96]
DEST[79:72] ← SRC2[103:96]
DEST[87:80] ← SRC1[111:104]
DEST[95:88] ← SRC2[111:104]
DEST[103:96] ← SRC1[119:112]
DEST[111:104] ← SRC2[119:112]
DEST[119:112] ← SRC1[127:120]
DEST[127:120] ← SRC2[127:120]
DEST[135:128] ← SRC1[199:192]
DEST[143:136] ← SRC2[199:192]
DEST[151:144] ← SRC1[207:200]
DEST[159:152] ← SRC2[207:200]
DEST[167:160] ← SRC1[215:208]
DEST[175:168] ← SRC2[215:208]
DEST[183:176] ← SRC1[223:216]
DEST[191:184] ← SRC2[223:216]
DEST[199:192] ← SRC1[231:224]
DEST[207:200] ← SRC2[231:224]
DEST[215:208] ← SRC1[239:232]
DEST[223:216] ← SRC2[239:232]
DEST[231:224] ← SRC1[247:240]
DEST[239:232] ← SRC2[247:240]
DEST[247:240] ← SRC1[255:248]
DEST[255:248] ← SRC2[255:248]
INTERLEAVE\_HIGH\_BYTES (SRC1, SRC2)
DEST[7:0] ← SRC1[71:64]
DEST[15:8] ← SRC2[71:64]
DEST[23:16] ← SRC1[79:72]
DEST[31:24] ← SRC2[79:72]
DEST[39:32] ← SRC1[87:80]
DEST[47:40] ← SRC2[87:80]
DEST[55:48] ← SRC1[95:88]
DEST[63:56] ← SRC2[95:88]
DEST[71:64] ← SRC1[103:96]
DEST[79:72] ← SRC2[103:96]
DEST[87:80] ← SRC1[111:104]
DEST[95:88] ← SRC2[111:104]
DEST[103:96] ← SRC1[119:112]
DEST[111:104] ← SRC2[119:112]
DEST[119:112] ← SRC1[127:120]
DEST[127:120] ← SRC2[127:120]
INTERLEAVE\_HIGH\_WORDS\_512b (SRC1, SRC2)
TMP\_DEST[255:0]←INTERLEAVE\_HIGH\_WORDS\_256b(SRC1[255:0], SRC[255:0])
TMP\_DEST[511:256]←INTERLEAVE\_HIGH\_WORDS\_256b(SRC1[511:256], SRC[511:256])
INTERLEAVE\_HIGH\_WORDS\_256b(SRC1, SRC2)
DEST[15:0] ← SRC1[79:64]
DEST[31:16] ← SRC2[79:64]
DEST[47:32] ← SRC1[95:80]
DEST[63:48] ← SRC2[95:80]
DEST[79:64] ← SRC1[111:96]
DEST[95:80] ← SRC2[111:96]
DEST[111:96] ← SRC1[127:112]
DEST[127:112] ← SRC2[127:112]
DEST[143:128] ← SRC1[207:192]
DEST[159:144] ← SRC2[207:192]
DEST[175:160] ← SRC1[223:208]
DEST[191:176] ← SRC2[223:208]
DEST[207:192] ← SRC1[239:224]
DEST[223:208] ← SRC2[239:224]
DEST[239:224] ← SRC1[255:240]
DEST[255:240] ← SRC2[255:240]
INTERLEAVE\_HIGH\_WORDS (SRC1, SRC2)
DEST[15:0] ← SRC1[79:64]
DEST[31:16] ← SRC2[79:64]
DEST[47:32] ← SRC1[95:80]
DEST[63:48] ← SRC2[95:80]
DEST[79:64] ← SRC1[111:96]
DEST[95:80] ← SRC2[111:96]
DEST[111:96] ← SRC1[127:112]
DEST[127:112] ← SRC2[127:112]
INTERLEAVE\_HIGH\_DWORDS\_512b (SRC1, SRC2)
TMP\_DEST[255:0]←INTERLEAVE\_HIGH\_DWORDS\_256b(SRC1[255:0], SRC2[255:0])
TMP\_DEST[511:256]←INTERLEAVE\_HIGH\_DWORDS\_256b(SRC1[511:256], SRC2[511:256])
INTERLEAVE\_HIGH\_DWORDS\_256b(SRC1, SRC2)
DEST[31:0] ← SRC1[95:64]
DEST[63:32] ← SRC2[95:64]
DEST[95:64] ← SRC1[127:96]
DEST[127:96] ← SRC2[127:96]
DEST[159:128] ← SRC1[223:192]
DEST[191:160] ← SRC2[223:192]
DEST[223:192] ← SRC1[255:224]
DEST[255:224] ← SRC2[255:224]
INTERLEAVE\_HIGH\_DWORDS(SRC1, SRC2)
DEST[31:0] ← SRC1[95:64]
DEST[63:32] ← SRC2[95:64]
DEST[95:64] ← SRC1[127:96]
DEST[127:96] ← SRC2[127:96]
INTERLEAVE\_HIGH\_QWORDS\_512b (SRC1, SRC2)
TMP\_DEST[255:0]←INTERLEAVE\_HIGH\_QWORDS\_256b(SRC1[255:0], SRC2[255:0])
TMP\_DEST[511:256]←INTERLEAVE\_HIGH\_QWORDS\_256b(SRC1[511:256], SRC2[511:256])
INTERLEAVE\_HIGH\_QWORDS\_256b(SRC1, SRC2)
DEST[63:0] ← SRC1[127:64]
DEST[127:64] ← SRC2[127:64]
DEST[191:128] ← SRC1[255:192]
DEST[255:192] ← SRC2[255:192]
INTERLEAVE\_HIGH\_QWORDS(SRC1, SRC2)
DEST[63:0] ← SRC1[127:64]
DEST[127:64] ← SRC2[127:64]

.fi
.RE

.SS PUNPCKHBW (128\-bit Legacy SSE Version)
.PP
.RS

.nf
DEST[127:0]←INTERLEAVE\_HIGH\_BYTES(DEST, SRC)
DEST[255:127] (Unmodified)

.fi
.RE

.SS VPUNPCKHBW (VEX.128 encoded version)
.PP
.RS

.nf
DEST[127:0]←INTERLEAVE\_HIGH\_BYTES(SRC1, SRC2)
DEST[MAXVL\-1:127] ←0

.fi
.RE

.SS VPUNPCKHBW (VEX.256 encoded version)
.PP
.RS

.nf
DEST[255:0]←INTERLEAVE\_HIGH\_BYTES\_256b(SRC1, SRC2)
DEST[MAXVL\-1:256] ←0

.fi
.RE

.SS VPUNPCKHBW (EVEX encoded versions)
.PP
.RS

.nf
(KL, VL) = (16, 128), (32, 256), (64, 512)
IF VL = 128
    TMP\_DEST[VL\-1:0]←INTERLEAVE\_HIGH\_BYTES(SRC1[VL\-1:0], SRC2[VL\-1:0])
FI;
IF VL = 256
    TMP\_DEST[VL\-1:0]←INTERLEAVE\_HIGH\_BYTES\_256b(SRC1[VL\-1:0], SRC2[VL\-1:0])
FI;
IF VL = 512
    TMP\_DEST[VL\-1:0]←INTERLEAVE\_HIGH\_BYTES\_512b(SRC1[VL\-1:0], SRC2[VL\-1:0])
FI;
FOR j←0 TO KL\-1
    i←j * 8
    IF k1[j] OR *no writemask*
        THEN DEST[i+7:i]←TMP\_DEST[i+7:i]
        ELSE
            IF *merging\-masking*
                        ; merging\-masking
                THEN *DEST[i+7:i] remains unchanged*
                ELSE *zeroing\-masking*
                            ; zeroing\-masking
                    DEST[i+7:i] ← 0
            FI
    FI;
ENDFOR
DEST[MAXVL\-1:VL] ← 0

.fi
.RE

.SS PUNPCKHWD (128\-bit Legacy SSE Version)
.PP
.RS

.nf
DEST[127:0]←INTERLEAVE\_HIGH\_WORDS(DEST, SRC)
DEST[255:127] (Unmodified)

.fi
.RE

.SS VPUNPCKHWD (VEX.128 encoded version)
.PP
.RS

.nf
DEST[127:0]←INTERLEAVE\_HIGH\_WORDS(SRC1, SRC2)
DEST[MAXVL\-1:127] ←0

.fi
.RE

.SS VPUNPCKHWD (VEX.256 encoded version)
.PP
.RS

.nf
DEST[255:0]←INTERLEAVE\_HIGH\_WORDS\_256b(SRC1, SRC2)
DEST[MAXVL\-1:256] ←0
VPUNPCKHWD (EVEX encoded versions)
(KL, VL) = (8, 128), (16, 256), (32, 512)
IF VL = 128
    TMP\_DEST[VL\-1:0]←INTERLEAVE\_HIGH\_WORDS(SRC1[VL\-1:0], SRC2[VL\-1:0])
FI;
IF VL = 256
    TMP\_DEST[VL\-1:0]←INTERLEAVE\_HIGH\_WORDS\_256b(SRC1[VL\-1:0], SRC2[VL\-1:0])
FI;
IF VL = 512
    TMP\_DEST[VL\-1:0]←INTERLEAVE\_HIGH\_WORDS\_512b(SRC1[VL\-1:0], SRC2[VL\-1:0])
FI;
FOR j←0 TO KL\-1
    i←j * 16
    IF k1[j] OR *no writemask*
        THEN DEST[i+15:i]←TMP\_DEST[i+15:i]
        ELSE
            IF *merging\-masking* ; merging\-masking
                THEN *DEST[i+15:i] remains unchanged*
                ELSE *zeroing\-masking*
                        ; zeroing\-masking
                    DEST[i+15:i] ← 0
            FI
    FI;
ENDFOR
DEST[MAXVL\-1:VL] ← 0

.fi
.RE

.SS PUNPCKHDQ (128\-bit Legacy SSE Version)
.PP
.RS

.nf
DEST[127:0]←INTERLEAVE\_HIGH\_DWORDS(DEST, SRC)
DEST[255:127] (Unmodified)

.fi
.RE

.SS VPUNPCKHDQ (VEX.128 encoded version)
.PP
.RS

.nf
DEST[127:0]←INTERLEAVE\_HIGH\_DWORDS(SRC1, SRC2)
DEST[MAXVL\-1:127] ←0

.fi
.RE

.SS VPUNPCKHDQ (VEX.256 encoded version)
.PP
.RS

.nf
DEST[255:0]←INTERLEAVE\_HIGH\_DWORDS\_256b(SRC1, SRC2)
DEST[MAXVL\-1:256] ←0

.fi
.RE

.SS VPUNPCKHDQ (EVEX.512 encoded version)
.PP
.RS

.nf
(KL, VL) = (4, 128), (8, 256), (16, 512)
FOR j←0 TO KL\-1
    i←j * 32
    IF (EVEX.b = 1) AND (SRC2 *is memory*)
        THEN TMP\_SRC2[i+31:i]←SRC2[31:0]
        ELSE TMP\_SRC2[i+31:i]←SRC2[i+31:i]
    FI;
ENDFOR;
IF VL = 128
    TMP\_DEST[VL\-1:0]←INTERLEAVE\_HIGH\_DWORDS(SRC1[VL\-1:0], TMP\_SRC2[VL\-1:0])
FI;
IF VL = 256
    TMP\_DEST[VL\-1:0]←INTERLEAVE\_HIGH\_DWORDS\_256b(SRC1[VL\-1:0], TMP\_SRC2[VL\-1:0])
FI;
IF VL = 512
    TMP\_DEST[VL\-1:0]←INTERLEAVE\_HIGH\_DWORDS\_512b(SRC1[VL\-1:0], TMP\_SRC2[VL\-1:0])
FI;
FOR j←0 TO KL\-1
    i←j * 32
    IF k1[j] OR *no writemask*
        THEN DEST[i+31:i]←TMP\_DEST[i+31:i]
        ELSE
            IF *merging\-masking*
                        ; merging\-masking
                THEN *DEST[i+31:i] remains unchanged*
                ELSE *zeroing\-masking*
                            ; zeroing\-masking
                    DEST[i+31:i] ← 0
            FI
    FI;
ENDFOR
DEST[MAXVL\-1:VL] ← 0

.fi
.RE

.SS PUNPCKHQDQ (128\-bit Legacy SSE Version)
.PP
.RS

.nf
DEST[127:0]←INTERLEAVE\_HIGH\_QWORDS(DEST, SRC)
DEST[MAXVL\-1:128] (Unmodified)

.fi
.RE

.SS VPUNPCKHQDQ (VEX.128 encoded version)
.PP
.RS

.nf
DEST[127:0]←INTERLEAVE\_HIGH\_QWORDS(SRC1, SRC2)
DEST[MAXVL\-1:128] ←0

.fi
.RE

.SS VPUNPCKHQDQ (VEX.256 encoded version)
.PP
.RS

.nf
DEST[255:0]←INTERLEAVE\_HIGH\_QWORDS\_256b(SRC1, SRC2)
DEST[MAXVL\-1:256] ←0

.fi
.RE

.SS VPUNPCKHQDQ (EVEX encoded versions)
.PP
.RS

.nf
(KL, VL) = (2, 128), (4, 256), (8, 512)
FOR j←0 TO KL\-1
    i←j * 64
    IF (EVEX.b = 1) AND (SRC2 *is memory*)
        THEN TMP\_SRC2[i+63:i]←SRC2[63:0]
        ELSE TMP\_SRC2[i+63:i]←SRC2[i+63:i]
    FI;
ENDFOR;
IF VL = 128
    TMP\_DEST[VL\-1:0]←INTERLEAVE\_HIGH\_QWORDS(SRC1[VL\-1:0], TMP\_SRC2[VL\-1:0])
FI;
IF VL = 256
    TMP\_DEST[VL\-1:0]←INTERLEAVE\_HIGH\_QWORDS\_256b(SRC1[VL\-1:0], TMP\_SRC2[VL\-1:0])
FI;
IF VL = 512
    TMP\_DEST[VL\-1:0]←INTERLEAVE\_HIGH\_QWORDS\_512b(SRC1[VL\-1:0], TMP\_SRC2[VL\-1:0])
FI;
FOR j←0 TO KL\-1
    i←j * 64
    IF k1[j] OR *no writemask*
        THEN DEST[i+63:i]←TMP\_DEST[i+63:i]
        ELSE
            IF *merging\-masking*
                        ; merging\-masking
                THEN *DEST[i+63:i] remains unchanged*
                ELSE *zeroing\-masking*
                            ; zeroing\-masking
                    DEST[i+63:i] ← 0
            FI
    FI;
ENDFOR
DEST[MAXVL\-1:VL] ← 0

.fi
.RE

.SH INTEL C/C++ COMPILER INTRINSIC EQUIVALENTS
.PP
.RS

.nf
VPUNPCKHBW \_\_m512i \_mm512\_unpackhi\_epi8(\_\_m512i a, \_\_m512i b);

VPUNPCKHBW \_\_m512i \_mm512\_mask\_unpackhi\_epi8(\_\_m512i s, \_\_mmask64 k, \_\_m512i a, \_\_m512i b);

VPUNPCKHBW \_\_m512i \_mm512\_maskz\_unpackhi\_epi8( \_\_mmask64 k, \_\_m512i a, \_\_m512i b);

VPUNPCKHBW \_\_m256i \_mm256\_mask\_unpackhi\_epi8(\_\_m256i s, \_\_mmask32 k, \_\_m256i a, \_\_m256i b);

VPUNPCKHBW \_\_m256i \_mm256\_maskz\_unpackhi\_epi8( \_\_mmask32 k, \_\_m256i a, \_\_m256i b);

VPUNPCKHBW \_\_m128i \_mm\_mask\_unpackhi\_epi8(v s, \_\_mmask16 k, \_\_m128i a, \_\_m128i b);

VPUNPCKHBW \_\_m128i \_mm\_maskz\_unpackhi\_epi8( \_\_mmask16 k, \_\_m128i a, \_\_m128i b);

VPUNPCKHWD \_\_m512i \_mm512\_unpackhi\_epi16(\_\_m512i a, \_\_m512i b);

VPUNPCKHWD \_\_m512i \_mm512\_mask\_unpackhi\_epi16(\_\_m512i s, \_\_mmask32 k, \_\_m512i a, \_\_m512i b);

VPUNPCKHWD \_\_m512i \_mm512\_maskz\_unpackhi\_epi16( \_\_mmask32 k, \_\_m512i a, \_\_m512i b);

VPUNPCKHWD \_\_m256i \_mm256\_mask\_unpackhi\_epi16(\_\_m256i s, \_\_mmask16 k, \_\_m256i a, \_\_m256i b);

VPUNPCKHWD \_\_m256i \_mm256\_maskz\_unpackhi\_epi16( \_\_mmask16 k, \_\_m256i a, \_\_m256i b);

VPUNPCKHWD \_\_m128i \_mm\_mask\_unpackhi\_epi16(v s, \_\_mmask8 k, \_\_m128i a, \_\_m128i b);

VPUNPCKHWD \_\_m128i \_mm\_maskz\_unpackhi\_epi16( \_\_mmask8 k, \_\_m128i a, \_\_m128i b);

VPUNPCKHDQ \_\_m512i \_mm512\_unpackhi\_epi32(\_\_m512i a, \_\_m512i b);

VPUNPCKHDQ \_\_m512i \_mm512\_mask\_unpackhi\_epi32(\_\_m512i s, \_\_mmask16 k, \_\_m512i a, \_\_m512i b);

VPUNPCKHDQ \_\_m512i \_mm512\_maskz\_unpackhi\_epi32( \_\_mmask16 k, \_\_m512i a, \_\_m512i b);

VPUNPCKHDQ \_\_m256i \_mm256\_mask\_unpackhi\_epi32(\_\_m512i s, \_\_mmask8 k, \_\_m512i a, \_\_m512i b);

VPUNPCKHDQ \_\_m256i \_mm256\_maskz\_unpackhi\_epi32( \_\_mmask8 k, \_\_m512i a, \_\_m512i b);

VPUNPCKHDQ \_\_m128i \_mm\_mask\_unpackhi\_epi32(\_\_m512i s, \_\_mmask8 k, \_\_m512i a, \_\_m512i b);

VPUNPCKHDQ \_\_m128i \_mm\_maskz\_unpackhi\_epi32( \_\_mmask8 k, \_\_m512i a, \_\_m512i b);

VPUNPCKHQDQ \_\_m512i \_mm512\_unpackhi\_epi64(\_\_m512i a, \_\_m512i b);

VPUNPCKHQDQ \_\_m512i \_mm512\_mask\_unpackhi\_epi64(\_\_m512i s, \_\_mmask8 k, \_\_m512i a, \_\_m512i b);

VPUNPCKHQDQ \_\_m512i \_mm512\_maskz\_unpackhi\_epi64( \_\_mmask8 k, \_\_m512i a, \_\_m512i b);

VPUNPCKHQDQ \_\_m256i \_mm256\_mask\_unpackhi\_epi64(\_\_m512i s, \_\_mmask8 k, \_\_m512i a, \_\_m512i b);

VPUNPCKHQDQ \_\_m256i \_mm256\_maskz\_unpackhi\_epi64( \_\_mmask8 k, \_\_m512i a, \_\_m512i b);

VPUNPCKHQDQ \_\_m128i \_mm\_mask\_unpackhi\_epi64(\_\_m512i s, \_\_mmask8 k, \_\_m512i a, \_\_m512i b);

VPUNPCKHQDQ \_\_m128i \_mm\_maskz\_unpackhi\_epi64( \_\_mmask8 k, \_\_m512i a, \_\_m512i b);

PUNPCKHBW:\_\_m64 \_mm\_unpackhi\_pi8(\_\_m64 m1, \_\_m64 m2)

(V)PUNPCKHBW:\_\_m128i \_mm\_unpackhi\_epi8(\_\_m128i m1, \_\_m128i m2)

VPUNPCKHBW:\_\_m256i \_mm256\_unpackhi\_epi8(\_\_m256i m1, \_\_m256i m2)

PUNPCKHWD:\_\_m64 \_mm\_unpackhi\_pi16(\_\_m64 m1,\_\_m64 m2)

(V)PUNPCKHWD:\_\_m128i \_mm\_unpackhi\_epi16(\_\_m128i m1,\_\_m128i m2)

VPUNPCKHWD:\_\_m256i \_mm256\_unpackhi\_epi16(\_\_m256i m1,\_\_m256i m2)

PUNPCKHDQ:\_\_m64 \_mm\_unpackhi\_pi32(\_\_m64 m1, \_\_m64 m2)

(V)PUNPCKHDQ:\_\_m128i \_mm\_unpackhi\_epi32(\_\_m128i m1, \_\_m128i m2)

VPUNPCKHDQ:\_\_m256i \_mm256\_unpackhi\_epi32(\_\_m256i m1, \_\_m256i m2)

(V)PUNPCKHQDQ:\_\_m128i \_mm\_unpackhi\_epi64 ( \_\_m128i a, \_\_m128i b)

VPUNPCKHQDQ:\_\_m256i \_mm256\_unpackhi\_epi64 ( \_\_m256i a, \_\_m256i b)

.fi
.RE

.SH FLAGS AFFECTED
.PP
None.

.SH NUMERIC EXCEPTIONS
.PP
None.

.SH OTHER EXCEPTIONS
.PP
Non\-EVEX\-encoded instruction, see Exceptions Type 4.

.PP
EVEX\-encoded VPUNPCKHQDQ/QDQ, see Exceptions Type E4NF.

.PP
EVEX\-encoded VPUNPCKHBW/WD, see Exceptions Type E4NF.nb.

.SH SEE ALSO
.PP
x86\-manpages(7) for a list of other x86\-64 man pages.

.SH COLOPHON
.PP
This UNOFFICIAL, mechanically\-separated, non\-verified reference is
provided for convenience, but it may be incomplete or broken in
various obvious or non\-obvious ways. Refer to Intel® 64 and IA\-32
Architectures Software Developer’s Manual for anything serious.

.br
This page is generated by scripts; therefore may contain visual or semantical bugs. Please report them (or better, fix them) on https://github.com/ttmo-O/x86-manpages.

.br
MIT licensed by TTMO 2020 (Turkish Unofficial Chamber of Reverse Engineers - https://ttmo.re).
