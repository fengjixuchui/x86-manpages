.nh
.TH "X86-VEXPANDPS" "7" "May 2019" "TTMO" "Intel x86-64 ISA Manual"
.SH NAME
VEXPANDPS - LOAD SPARSE PACKED SINGLE-PRECISION FLOATING-POINT VALUES FROM DENSE MEMORY
.TS
allbox;
l l l l l 
l l l l l .
\fB\fCOpcode/Instruction\fR	\fB\fCOp/En\fR	\fB\fC64/32 bit Mode Support\fR	\fB\fCCPUID Feature Flag\fR	\fB\fCDescription\fR
T{
EVEX.128.66.0F38.W0 88 /r VEXPANDPS xmm1 {k1}{z}, xmm2/m128
T}
	A	V/V	AVX512VL AVX512F	T{
Expand packed single\-precision floating\-point values from xmm2/m128 to xmm1 using writemask k1.
T}
T{
EVEX.256.66.0F38.W0 88 /r VEXPANDPS ymm1 {k1}{z}, ymm2/m256
T}
	A	V/V	AVX512VL AVX512F	T{
Expand packed single\-precision floating\-point values from ymm2/m256 to ymm1 using writemask k1.
T}
T{
EVEX.512.66.0F38.W0 88 /r VEXPANDPS zmm1 {k1}{z}, zmm2/m512
T}
	A	V/V	AVX512F	T{
Expand packed single\-precision floating\-point values from zmm2/m512 to zmm1 using writemask k1.
T}
.TE

.SH INSTRUCTION OPERAND ENCODING
.TS
allbox;
l l l l l l 
l l l l l l .
Op/En	Tuple Type	Operand 1	Operand 2	Operand 3	Operand 4
A	Tuple1 Scalar	ModRM:reg (w)	ModRM:r/m (r)	NA	NA
.TE

.SS Description
.PP
Expand (load) up to 16/8/4, contiguous, single\-precision floating\-point
values of the input vector in the source operand (the second operand) to
sparse elements of the destination operand (the first operand) selected
by the writemask k1.

.PP
The destination operand is a ZMM/YMM/XMM register, the source operand
can be a ZMM/YMM/XMM register or a 512/256/128\-bit memory location.

.PP
The input vector starts from the lowest element in the source operand.
The writemask k1 selects the destination elements (a partial vector or
sparse elements if less than 16 elements) to be replaced by the
ascending elements in the input vector. Destination elements not
selected by the writemask k1 are either unmodified or zeroed, depending
on EVEX.z.

.PP
EVEX.vvvv is reserved and must be 1111b otherwise instructions will
#UD.

.PP
Note that the compressed displacement assumes a pre\-scaling (N)
corresponding to the size of one single element instead of the size of
the full vector.

.SS Operation
.SS VEXPANDPS (EVEX encoded versions)
.PP
.RS

.nf
(KL, VL) = (4, 128), (8, 256), (16, 512)
k←0
FOR j←0 TO KL\-1
    i←j * 32
    IF k1[j] OR *no writemask*
        THEN
            DEST[i+31:i] ← SRC[k+31:k];
            k←k + 32
        ELSE
            IF *merging\-masking*
                        ; merging\-masking
                THEN *DEST[i+31:i] remains unchanged*
                ELSE
                        ; zeroing\-masking
                    DEST[i+31:i] ← 0
            FI
    FI;
ENDFOR
DEST[MAXVL\-1:VL] ← 0

.fi
.RE

.SS Intel C/C++ Compiler Intrinsic Equivalent
.PP
.RS

.nf
VEXPANDPS \_\_m512 \_mm512\_mask\_expand\_ps( \_\_m512 s, \_\_mmask16 k, \_\_m512 a);

VEXPANDPS \_\_m512 \_mm512\_maskz\_expand\_ps( \_\_mmask16 k, \_\_m512 a);

VEXPANDPS \_\_m512 \_mm512\_mask\_expandloadu\_ps( \_\_m512 s, \_\_mmask16 k, void * a);

VEXPANDPS \_\_m512 \_mm512\_maskz\_expandloadu\_ps( \_\_mmask16 k, void * a);

VEXPANDPD \_\_m256 \_mm256\_mask\_expand\_ps( \_\_m256 s, \_\_mmask8 k, \_\_m256 a);

VEXPANDPD \_\_m256 \_mm256\_maskz\_expand\_ps( \_\_mmask8 k, \_\_m256 a);

VEXPANDPD \_\_m256 \_mm256\_mask\_expandloadu\_ps( \_\_m256 s, \_\_mmask8 k, void * a);

VEXPANDPD \_\_m256 \_mm256\_maskz\_expandloadu\_ps( \_\_mmask8 k, void * a);

VEXPANDPD \_\_m128 \_mm\_mask\_expand\_ps( \_\_m128 s, \_\_mmask8 k, \_\_m128 a);

VEXPANDPD \_\_m128 \_mm\_maskz\_expand\_ps( \_\_mmask8 k, \_\_m128 a);

VEXPANDPD \_\_m128 \_mm\_mask\_expandloadu\_ps( \_\_m128 s, \_\_mmask8 k, void * a);

VEXPANDPD \_\_m128 \_mm\_maskz\_expandloadu\_ps( \_\_mmask8 k, void * a);

.fi
.RE

.SS SIMD Floating\-Point Exceptions
.PP
None

.SS Other Exceptions
.PP
See Exceptions Type E4.nb.

.TS
allbox;
l l 
l l .
#UD	If EVEX.vvvv != 1111B.
.TE

.SH SEE ALSO
.PP
x86\-manpages(7) for a list of other x86\-64 man pages.

.SH COLOPHON
.PP
This UNOFFICIAL, mechanically\-separated, non\-verified reference is
provided for convenience, but it may be incomplete or broken in
various obvious or non\-obvious ways. Refer to Intel® 64 and IA\-32
Architectures Software Developer’s Manual for anything serious.

.br
This page is generated by scripts; therefore may contain visual or semantical bugs. Please report them (or better, fix them) on https://github.com/ttmo-O/x86-manpages.

.br
MIT licensed by TTMO 2020 (Turkish Unofficial Chamber of Reverse Engineers - https://ttmo.re).
