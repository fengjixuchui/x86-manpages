.nh
.TH "X86-PABSB-PABSW-PABSD-PABSQ" "7" "May 2019" "TTMO" "Intel x86-64 ISA Manual"
.SH NAME
PABSB-PABSW-PABSD-PABSQ - PACKED ABSOLUTE VALUE
.TS
allbox;
l l l l l 
l l l l l .
\fB\fCOpcode/Instruction\fR	\fB\fCOp/En\fR	\fB\fC64/32 bit Mode Support\fR	\fB\fCCPUID Feature Flag\fR	\fB\fCDescription\fR
T{
NP 0F 38 1C /r1 PABSB mm1, mm2/m64
T}
	A	V/V	SSSE3	T{
Compute the absolute value of bytes in mm1.
T}
T{
66 0F 38 1C /r PABSB xmm1, xmm2/m128
T}
	A	V/V	SSSE3	T{
Compute the absolute value of bytes in xmm1.
T}
T{
NP 0F 38 1D /r1 PABSW mm1, mm2/m64
T}
	A	V/V	SSSE3	T{
Compute the absolute value of 16\-bit integers in mm1.
T}
T{
66 0F 38 1D /r PABSW xmm1, xmm2/m128
T}
	A	V/V	SSSE3	T{
Compute the absolute value of 16\-bit integers in xmm1.
T}
T{
NP 0F 38 1E /r1 PABSD mm1, mm2/m64
T}
	A	V/V	SSSE3	T{
Compute the absolute value of 32\-bit integers in mm1.
T}
T{
66 0F 38 1E /r PABSD xmm1, xmm2/m128
T}
	A	V/V	SSSE3	T{
Compute the absolute value of 32\-bit integers in xmm1.
T}
T{
VEX.128.66.0F38.WIG 1C /r VPABSB xmm1, xmm2/m128
T}
	A	V/V	AVX	T{
Compute the absolute value of bytes in xmm1.
T}
T{
VEX.128.66.0F38.WIG 1D /r VPABSW xmm1, xmm2/m128
T}
	A	V/V	AVX	T{
Compute the absolute value of 16\- bit integers in xmm1.
T}
T{
VEX.128.66.0F38.WIG 1E /r VPABSD xmm1, xmm2/m128
T}
	A	V/V	AVX	T{
Compute the absolute value of 32\- bit integers in xmm1.
T}
T{
VEX.256.66.0F38.WIG 1C /r VPABSB ymm1, ymm2/m256
T}
	A	V/V	AVX2	T{
Compute the absolute value of bytes in ymm1.
T}
T{
VEX.256.66.0F38.WIG 1D /r VPABSW ymm1, ymm2/m256
T}
	A	V/V	AVX2	T{
Compute the absolute value of 16\-bit integers in ymm1.
T}
T{
VEX.256.66.0F38.WIG 1E /r VPABSD ymm1, ymm2/m256
T}
	A	V/V	AVX2	T{
Compute the absolute value of 32\-bit integers in ymm1.
T}
T{
EVEX.128.66.0F38.WIG 1C /r VPABSB xmm1 {k1}{z}, xmm2/m128
T}
	B	V/V	AVX512VL AVX512BW	T{
Compute the absolute value of bytes in xmm2/m128 and store UNSIGNED result in xmm1 using writemask k1.
T}
T{
EVEX.256.66.0F38.WIG 1C /r VPABSB ymm1 {k1}{z}, ymm2/m256
T}
	B	V/V	AVX512VL AVX512BW	T{
Compute the absolute value of bytes in ymm2/m256 and store UNSIGNED result in ymm1 using writemask k1.
T}
T{
EVEX.512.66.0F38.WIG 1C /r VPABSB zmm1 {k1}{z}, zmm2/m512
T}
	B	V/V	AVX512BW	T{
Compute the absolute value of bytes in zmm2/m512 and store UNSIGNED result in zmm1 using writemask k1.
T}
T{
EVEX.128.66.0F38.WIG 1D /r VPABSW xmm1 {k1}{z}, xmm2/m128
T}
	B	V/V	AVX512VL AVX512BW	T{
Compute the absolute value of 16\-bit integers in xmm2/m128 and store UNSIGNED result in xmm1 using writemask k1.
T}
.TE

.TS
allbox;
l l l l l 
l l l l l .
T{
EVEX.256.66.0F38.WIG 1D /r VPABSW ymm1 {k1}{z}, ymm2/m256
T}
	B	V/V	AVX512VL AVX512BW	T{
Compute the absolute value of 16\-bit integers in ymm2/m256 and store UNSIGNED result in ymm1 using writemask k1.
T}
T{
EVEX.512.66.0F38.WIG 1D /r VPABSW zmm1 {k1}{z}, zmm2/m512
T}
	B	V/V	AVX512BW	T{
Compute the absolute value of 16\-bit integers in zmm2/m512 and store UNSIGNED result in zmm1 using writemask k1.
T}
T{
EVEX.128.66.0F38.W0 1E /r VPABSD xmm1 {k1}{z}, xmm2/m128/m32bcst
T}
	C	V/V	AVX512VL AVX512F	T{
Compute the absolute value of 32\-bit integers in xmm2/m128/m32bcst and store UNSIGNED result in xmm1 using writemask k1.
T}
T{
EVEX.256.66.0F38.W0 1E /r VPABSD ymm1 {k1}{z}, ymm2/m256/m32bcst
T}
	C	V/V	AVX512VL AVX512F	T{
Compute the absolute value of 32\-bit integers in ymm2/m256/m32bcst and store UNSIGNED result in ymm1 using writemask k1.
T}
T{
EVEX.512.66.0F38.W0 1E /r VPABSD zmm1 {k1}{z}, zmm2/m512/m32bcst
T}
	C	V/V	AVX512F	T{
Compute the absolute value of 32\-bit integers in zmm2/m512/m32bcst and store UNSIGNED result in zmm1 using writemask k1.
T}
T{
EVEX.128.66.0F38.W1 1F /r VPABSQ xmm1 {k1}{z}, xmm2/m128/m64bcst
T}
	C	V/V	AVX512VL AVX512F	T{
Compute the absolute value of 64\-bit integers in xmm2/m128/m64bcst and store UNSIGNED result in xmm1 using writemask k1.
T}
T{
EVEX.256.66.0F38.W1 1F /r VPABSQ ymm1 {k1}{z}, ymm2/m256/m64bcst
T}
	C	V/V	AVX512VL AVX512F	T{
Compute the absolute value of 64\-bit integers in ymm2/m256/m64bcst and store UNSIGNED result in ymm1 using writemask k1.
T}
T{
EVEX.512.66.0F38.W1 1F /r VPABSQ zmm1 {k1}{z}, zmm2/m512/m64bcst
T}
	C	V/V	AVX512F	T{
Compute the absolute value of 64\-bit integers in zmm2/m512/m64bcst and store UNSIGNED result in zmm1 using writemask k1.
T}
.TE

.PP
.RS

.PP
1\&. See note in Section 2.4, “AVX and SSE Instruction Exception
Specification” in the Intel® 64 and IA\-32 Architectures Software
Developer’s Manual, Volume 3A.

.RE

.SH INSTRUCTION OPERAND ENCODING
.TS
allbox;
l l l l l l 
l l l l l l .
Op/En	Tuple Type	Operand 1	Operand 2	Operand 3	Operand 4
A	NA	ModRM:reg (w)	ModRM:r/m (r)	NA	NA
B	Full Mem	ModRM:reg (w)	ModRM:r/m (r)	NA	NA
C	Full	ModRM:reg (w)	ModRM:r/m (r)	NA	NA
.TE

.SH DESCRIPTION
.PP
PABSB/W/D computes the absolute value of each data element of the source
operand (the second operand) and stores the UNSIGNED results in the
destination operand (the first operand). PABSB operates on signed bytes,
PABSW operates on signed 16\-bit words, and PABSD operates on signed
32\-bit integers.

.PP
EVEX encoded VPABSD/Q: The source operand is a ZMM/YMM/XMM register, a
512/256/128\-bit memory location, or a 512/256/128\-bit vector broadcasted
from a 32/64\-bit memory location. The destination operand is a
ZMM/YMM/XMM register updated according to the writemask.

.PP
EVEX encoded VPABSB/W: The source operand is a ZMM/YMM/XMM register, or
a 512/256/128\-bit memory location. The destination operand is a
ZMM/YMM/XMM register updated according to the writemask.

.PP
VEX.256 encoded versions: The source operand is a YMM register or a
256\-bit memory location. The destination operand is a YMM register. The
upper bits (MAXVL\-1:256) of the corresponding register destination are
zeroed.

.PP
VEX.128 encoded versions: The source operand is an XMM register or
128\-bit memory location. The destination operand is an XMM register. The
upper bits (MAXVL\-1:128) of the corresponding register destination are
zeroed.

.PP
128\-bit Legacy SSE version: The source operand can be an XMM register or
an 128\-bit memory location. The destination is an XMM register. The
upper bits (VL\_MAX\-1:128) of the corresponding register destination are
unmodified.

.PP
VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise
instructions will #UD.

.SS Operation
.SS PABSB with 128 bit operands:
.PP
.RS

.nf
Unsigned DEST[7:0]←ABS(SRC[7: 0])
Repeat operation for 2nd through 15th bytes
Unsigned DEST[127:120]←ABS(SRC[127:120])

.fi
.RE

.SS VPABSB with 128 bit operands:
.PP
.RS

.nf
Unsigned DEST[7:0]←ABS(SRC[7: 0])
Repeat operation for 2nd through 15th bytes
Unsigned DEST[127:120]←ABS(SRC[127:120])

.fi
.RE

.SS VPABSB with 256 bit operands:
.PP
.RS

.nf
Unsigned DEST[7:0]←ABS(SRC[7: 0])
Repeat operation for 2nd through 31st bytes
Unsigned DEST[255:248]←ABS(SRC[255:248])

.fi
.RE

.SS VPABSB (EVEX encoded versions)
.PP
.RS

.nf
    (KL, VL) = (16, 128), (32, 256), (64, 512)
FOR j←0 TO KL\-1
    i←j * 8
    IF k1[j] OR *no writemask*
        THEN
            Unsigned DEST[i+7:i]←ABS(SRC[i+7:i])
        ELSE
            IF *merging\-masking* ; merging\-masking
                THEN *DEST[i+7:i] remains unchanged*
                ELSE *zeroing\-masking*
                        ; zeroing\-masking
                    DEST[i+7:i] ← 0
            FI
    FI;
ENDFOR;
DEST[MAXVL\-1:VL] ← 0

.fi
.RE

.SS PABSW with 128 bit operands:
.PP
.RS

.nf
Unsigned DEST[15:0]←ABS(SRC[15:0])
Repeat operation for 2nd through 7th 16\-bit words
Unsigned DEST[127:112]←ABS(SRC[127:112])

.fi
.RE

.SS VPABSW with 128 bit operands:
.PP
.RS

.nf
Unsigned DEST[15:0]←ABS(SRC[15:0])
Repeat operation for 2nd through 7th 16\-bit words
Unsigned DEST[127:112]←ABS(SRC[127:112])

.fi
.RE

.SS VPABSW with 256 bit operands:
.PP
.RS

.nf
Unsigned DEST[15:0]←ABS(SRC[15:0])
Repeat operation for 2nd through 15th 16\-bit words
Unsigned DEST[255:240]←ABS(SRC[255:240])

.fi
.RE

.SS VPABSW (EVEX encoded versions)
.PP
.RS

.nf
    (KL, VL) = (8, 128), (16, 256), (32, 512)
FOR j←0 TO KL\-1
    i←j * 16
    IF k1[j] OR *no writemask*
        THEN
            Unsigned DEST[i+15:i]←ABS(SRC[i+15:i])
        ELSE
            IF *merging\-masking* ; merging\-masking
                THEN *DEST[i+15:i] remains unchanged*
                ELSE *zeroing\-masking* ; zeroing\-masking
                    DEST[i+15:i] ← 0
            FI
    FI;
ENDFOR;
DEST[MAXVL\-1:VL] ← 0

.fi
.RE

.SS PABSD with 128 bit operands:
.PP
.RS

.nf
Unsigned DEST[31:0]←ABS(SRC[31:0])
Repeat operation for 2nd through 3rd 32\-bit double words
Unsigned DEST[127:96]←ABS(SRC[127:96])

.fi
.RE

.SS VPABSD with 128 bit operands:
.PP
.RS

.nf
Unsigned DEST[31:0]←ABS(SRC[31:0])
Repeat operation for 2nd through 3rd 32\-bit double words
Unsigned DEST[127:96]←ABS(SRC[127:96])

.fi
.RE

.SS VPABSD with 256 bit operands:
.PP
.RS

.nf
Unsigned DEST[31:0]←ABS(SRC[31:0])
Repeat operation for 2nd through 7th 32\-bit double words
Unsigned DEST[255:224]←ABS(SRC[255:224])

.fi
.RE

.SS VPABSD (EVEX encoded versions)
.PP
.RS

.nf
(KL, VL) = (4, 128), (8, 256), (16, 512)
FOR j←0 TO KL\-1
    i←j * 32
    IF k1[j] OR *no writemask*
        THEN
            IF (EVEX.b = 1) AND (SRC *is memory*)
                THEN
                    Unsigned DEST[i+31:i]←ABS(SRC[31:0])
                ELSE
                    Unsigned DEST[i+31:i]←ABS(SRC[i+31:i])
            FI;
        ELSE
            IF *merging\-masking* ; merging\-masking
                THEN *DEST[i+31:i] remains unchanged*
                ELSE *zeroing\-masking*
                        ; zeroing\-masking
                    DEST[i+31:i] ← 0
            FI
    FI;
ENDFOR;
DEST[MAXVL\-1:VL] ← 0

.fi
.RE

.SS VPABSQ (EVEX encoded versions)
.PP
.RS

.nf
(KL, VL) = (2, 128), (4, 256), (8, 512)
FOR j←0 TO KL\-1
    i←j * 64
    IF k1[j] OR *no writemask*
        THEN
            IF (EVEX.b = 1) AND (SRC *is memory*)
                THEN
                    Unsigned DEST[i+63:i]←ABS(SRC[63:0])
                ELSE
                    Unsigned DEST[i+63:i]←ABS(SRC[i+63:i])
            FI;
        ELSE
            IF *merging\-masking* ; merging\-masking
                THEN *DEST[i+63:i] remains unchanged*
                ELSE *zeroing\-masking*
                        ; zeroing\-masking
                    DEST[i+63:i] ← 0
            FI
    FI;
ENDFOR;
DEST[MAXVL\-1:VL] ← 0

.fi
.RE

.SS Intel C/C++ Compiler Intrinsic Equivalents
.PP
.RS

.nf
VPABSB\_\_m512i \_mm512\_abs\_epi8 ( \_\_m512i a)

VPABSW\_\_m512i \_mm512\_abs\_epi16 ( \_\_m512i a)

VPABSB\_\_m512i \_mm512\_mask\_abs\_epi8 ( \_\_m512i s, \_\_mmask64 m, \_\_m512i a)

VPABSW\_\_m512i \_mm512\_mask\_abs\_epi16 ( \_\_m512i s, \_\_mmask32 m, \_\_m512i a)

VPABSB\_\_m512i \_mm512\_maskz\_abs\_epi8 (\_\_mmask64 m, \_\_m512i a)

VPABSW\_\_m512i \_mm512\_maskz\_abs\_epi16 (\_\_mmask32 m, \_\_m512i a)

VPABSB\_\_m256i \_mm256\_mask\_abs\_epi8 (\_\_m256i s, \_\_mmask32 m, \_\_m256i a)

VPABSW\_\_m256i \_mm256\_mask\_abs\_epi16 (\_\_m256i s, \_\_mmask16 m, \_\_m256i a)

VPABSB\_\_m256i \_mm256\_maskz\_abs\_epi8 (\_\_mmask32 m, \_\_m256i a)

VPABSW\_\_m256i \_mm256\_maskz\_abs\_epi16 (\_\_mmask16 m, \_\_m256i a)

VPABSB\_\_m128i \_mm\_mask\_abs\_epi8 (\_\_m128i s, \_\_mmask16 m, \_\_m128i a)

VPABSW\_\_m128i \_mm\_mask\_abs\_epi16 (\_\_m128i s, \_\_mmask8 m, \_\_m128i a)

VPABSB\_\_m128i \_mm\_maskz\_abs\_epi8 (\_\_mmask16 m, \_\_m128i a)

VPABSW\_\_m128i \_mm\_maskz\_abs\_epi16 (\_\_mmask8 m, \_\_m128i a)

VPABSD \_\_m256i \_mm256\_mask\_abs\_epi32(\_\_m256i s, \_\_mmask8 k, \_\_m256i a);

VPABSD \_\_m256i \_mm256\_maskz\_abs\_epi32( \_\_mmask8 k, \_\_m256i a);

VPABSD \_\_m128i \_mm\_mask\_abs\_epi32(\_\_m128i s, \_\_mmask8 k, \_\_m128i a);

VPABSD \_\_m128i \_mm\_maskz\_abs\_epi32( \_\_mmask8 k, \_\_m128i a);

VPABSD \_\_m512i \_mm512\_abs\_epi32( \_\_m512i a);

VPABSD \_\_m512i \_mm512\_mask\_abs\_epi32(\_\_m512i s, \_\_mmask16 k, \_\_m512i a);

VPABSD \_\_m512i \_mm512\_maskz\_abs\_epi32( \_\_mmask16 k, \_\_m512i a);

VPABSQ \_\_m512i \_mm512\_abs\_epi64( \_\_m512i a);

VPABSQ \_\_m512i \_mm512\_mask\_abs\_epi64(\_\_m512i s, \_\_mmask8 k, \_\_m512i a);

VPABSQ \_\_m512i \_mm512\_maskz\_abs\_epi64( \_\_mmask8 k, \_\_m512i a);

VPABSQ \_\_m256i \_mm256\_mask\_abs\_epi64(\_\_m256i s, \_\_mmask8 k, \_\_m256i a);

VPABSQ \_\_m256i \_mm256\_maskz\_abs\_epi64( \_\_mmask8 k, \_\_m256i a);

VPABSQ \_\_m128i \_mm\_mask\_abs\_epi64(\_\_m128i s, \_\_mmask8 k, \_\_m128i a);

VPABSQ \_\_m128i \_mm\_maskz\_abs\_epi64( \_\_mmask8 k, \_\_m128i a);

PABSB \_\_m128i \_mm\_abs\_epi8 (\_\_m128i a)

VPABSB \_\_m128i \_mm\_abs\_epi8 (\_\_m128i a)

VPABSB \_\_m256i \_mm256\_abs\_epi8 (\_\_m256i a)

PABSW \_\_m128i \_mm\_abs\_epi16 (\_\_m128i a)

VPABSW \_\_m128i \_mm\_abs\_epi16 (\_\_m128i a)

VPABSW \_\_m256i \_mm256\_abs\_epi16 (\_\_m256i a)

PABSD \_\_m128i \_mm\_abs\_epi32 (\_\_m128i a)

VPABSD \_\_m128i \_mm\_abs\_epi32 (\_\_m128i a)

VPABSD \_\_m256i \_mm256\_abs\_epi32 (\_\_m256i a)

.fi
.RE

.SS SIMD Floating\-Point Exceptions
.PP
None

.SS Other Exceptions
.PP
Non\-EVEX\-encoded instruction, see Exceptions Type 4.

.PP
EVEX\-encoded VPABSD/Q, see Exceptions Type E4.

.PP
EVEX\-encoded VPABSB/W, see Exceptions Type E4.nb.

.SH SEE ALSO
.PP
x86\-manpages(7) for a list of other x86\-64 man pages.

.SH COLOPHON
.PP
This UNOFFICIAL, mechanically\-separated, non\-verified reference is
provided for convenience, but it may be incomplete or broken in
various obvious or non\-obvious ways. Refer to Intel® 64 and IA\-32
Architectures Software Developer’s Manual for anything serious.

.br
This page is generated by scripts; therefore may contain visual or semantical bugs. Please report them (or better, fix them) on https://github.com/ttmo-O/x86-manpages.

.br
MIT licensed by TTMO 2020 (Turkish Unofficial Chamber of Reverse Engineers - https://ttmo.re).
