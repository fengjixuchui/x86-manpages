.nh
.TH "X86-VPERMB" "7" "May 2019" "TTMO" "Intel x86-64 ISA Manual"
.SH NAME
VPERMB - PERMUTE PACKED BYTES ELEMENTS
.TS
allbox;
l l l l l 
l l l l l .
\fB\fCOpcode/Instruction\fR	\fB\fCOp/En\fR	\fB\fC64/32 bit Mode Support\fR	\fB\fCCPUID Feature Flag\fR	\fB\fCDescription\fR
T{
EVEX.128.66.0F38.W0 8D /r VPERMB xmm1 {k1}{z}, xmm2, xmm3/m128
T}
	A	V/V	AVX512VL AVX512\_VBMI	T{
Permute bytes in xmm3/m128 using byte indexes in xmm2 and store the result in xmm1 using writemask k1.
T}
T{
EVEX.256.66.0F38.W0 8D /r VPERMB ymm1 {k1}{z}, ymm2, ymm3/m256
T}
	A	V/V	AVX512VL AVX512\_VBMI	T{
Permute bytes in ymm3/m256 using byte indexes in ymm2 and store the result in ymm1 using writemask k1.
T}
T{
EVEX.512.66.0F38.W0 8D /r VPERMB zmm1 {k1}{z}, zmm2, zmm3/m512
T}
	A	V/V	AVX512\_VBMI	T{
Permute bytes in zmm3/m512 using byte indexes in zmm2 and store the result in zmm1 using writemask k1.
T}
.TE

.SH INSTRUCTION OPERAND ENCODING
.TS
allbox;
l l l l l l 
l l l l l l .
Op/En	Tuple Type	Operand 1	Operand 2	Operand 3	Operand 4
A	Full Mem	ModRM:reg (w)	EVEX.vvvv (r)	ModRM:r/m (r)	NA
.TE

.SS Description
.PP
Copies bytes from the second source operand (the third operand) to the
destination operand (the first operand) according to the byte indices in
the first source operand (the second operand). Note that this
instruction permits a byte in the source operand to be copied to more
than one location in the destination operand.

.PP
Only the low 6(EVEX.512)/5(EVEX.256)/4(EVEX.128) bits of each byte index
is used to select the location of the source byte from the second source
operand.

.PP
The first source operand is a ZMM/YMM/XMM register. The second source
operand can be a ZMM/YMM/XMM register, a 512/256/128\-bit memory
location. The destination operand is a ZMM/YMM/XMM register updated at
byte granularity by the writemask k1.

.SS Operation
.SS VPERMB (EVEX encoded versions)
.PP
.RS

.nf
(KL, VL) = (16, 128), (32, 256), (64, 512)
IF VL = 128:
    n ← 3;
ELSE IF VL = 256:
    n ← 4;
ELSE IF VL = 512:
    n ← 5;
FI;
FOR j ← 0 TO KL\-1:
    id ← SRC1[j*8 + n : j*8] ; // location of the source byte
    IF k1[j] OR *no writemask* THEN
        DEST[j*8 + 7: j*8] ← SRC2[id*8 +7: id*8];
    ELSE IF zeroing\-masking THEN
        DEST[j*8 + 7: j*8] ← 0;
    *ELSE
        DEST[j*8 + 7: j*8] remains unchanged*
    FI
ENDFOR
DEST[MAX\_VL\-1:VL] ← 0;

.fi
.RE

.SS Intel C/C++ Compiler Intrinsic Equivalent
.PP
.RS

.nf
VPERMB \_\_m512i \_mm512\_permutexvar\_epi8( \_\_m512i idx, \_\_m512i a);

VPERMB \_\_m512i \_mm512\_mask\_permutexvar\_epi8(\_\_m512i s, \_\_mmask64 k, \_\_m512i idx, \_\_m512i a);

VPERMB \_\_m512i \_mm512\_maskz\_permutexvar\_epi8( \_\_mmask64 k, \_\_m512i idx, \_\_m512i a);

VPERMB \_\_m256i \_mm256\_permutexvar\_epi8( \_\_m256i idx, \_\_m256i a);

VPERMB \_\_m256i \_mm256\_mask\_permutexvar\_epi8(\_\_m256i s, \_\_mmask32 k, \_\_m256i idx, \_\_m256i a);

VPERMB \_\_m256i \_mm256\_maskz\_permutexvar\_epi8( \_\_mmask32 k, \_\_m256i idx, \_\_m256i a);

VPERMB \_\_m128i \_mm\_permutexvar\_epi8( \_\_m128i idx, \_\_m128i a);

VPERMB \_\_m128i \_mm\_mask\_permutexvar\_epi8(\_\_m128i s, \_\_mmask16 k, \_\_m128i idx, \_\_m128i a);

VPERMB \_\_m128i \_mm\_maskz\_permutexvar\_epi8( \_\_mmask16 k, \_\_m128i idx, \_\_m128i a);

.fi
.RE

.SS SIMD Floating\-Point Exceptions
.PP
None.

.SS Other Exceptions
.PP
See Exceptions Type E4NF.nb.

.SH SEE ALSO
.PP
x86\-manpages(7) for a list of other x86\-64 man pages.

.SH COLOPHON
.PP
This UNOFFICIAL, mechanically\-separated, non\-verified reference is
provided for convenience, but it may be incomplete or broken in
various obvious or non\-obvious ways. Refer to Intel® 64 and IA\-32
Architectures Software Developer’s Manual for anything serious.

.br
This page is generated by scripts; therefore may contain visual or semantical bugs. Please report them (or better, fix them) on https://github.com/ttmo-O/x86-manpages.

.br
MIT licensed by TTMO 2020 (Turkish Unofficial Chamber of Reverse Engineers - https://ttmo.re).
